{
  "desktop.ini": "[.ShellClassInfo]\nIconResource=D:\\Icons\\logos--highcharts.ico,0\n[ViewState]\nMode=\nVid=\nFolderType=Generic\n",
  "markdownLearn\\Latex数学排版.md": "# Latex数学公式语法\n### 基本语法\n- 上标: $a^2$  下标: $a_2$\n- 加减: $a+b$ $a-b$  叉乘: $a \\times b$  点乘: $a \\cdot b$  两点除: $a \\div b$\n- 等于: $a=b$  不等于: $a \\neq b$  约等于: $a \\approx b$  恒等于: $a \\equiv b$\n- 大于: $a>b$  小于: $a<b$  大于等于: $a \\geq b$  小于等于: $a \\leq b$  远大于: $a \\gg b$  远小于: $a \\ll b$\n- 绝对值: $|a|$ 阶乘: $a!$  \n- 分数: $\\frac{a}{b}$\n- 换行:\n$$\n\\begin{array}{l}\n\\Psi_{12}=N_1\\Phi_{12}=N_1 B_2 S_2 \\\\\n\\Psi_{21}=N_2\\Phi_{21}=N_2 B_{1中心} S_2\n\\end{array}\n$$\n- 平方根: $\\sqrt{a}$  高次方根: $\\sqrt[n]{a}$\n- 对数: $\\log_{2}a$   $\\ln a$\n- 三角函数: $\\sin \\theta, \\cos \\theta, \\tan \\theta$\n- 导数: $x'$  微分: $\\frac{d}{dx} f(x)$  偏微分: $\\frac{\\partial f}{\\partial a}$\n- 括号: $\\left( \\right), \\left[ \\right], \\left\\langle \\right\\rangle,\\left\\{ \\right\\}$\n\n- 求和:  $$\\sum_{i=1}^{5} i^2+2i-1$$\n- 求积:$$\\prod_{i=1}^{\\infty}\\frac{1}{n^2}$$\n- 求极限:$$lim_{x \\to \\infty} f(x)$$\n- 求积分:$$\\int_{a}^{b} f(x)dx$$\n- 多重积分: $$\\iint_S f(x,y)dxdy$$  $$\\iiint_S f(x,y)dxdy$$\n- 曲线积分和曲面积分:$$\\oint_C \\mathbf{F} \\cdot d\\mathbf{r} = 0$$ $$\\oint_C \\mathbf{F} \\cdot d\\mathbf{r} = 0$$\n- 多行等号对齐公式:\n$$\n\\begin{align}\nf(x) & = (a+b)^2 \\\\\n& = a^2+2ab+b^2\n\\end{align}\n$$\n- 多行公式(各自对齐):\n$$\n\\begin{array}{clc}\nz & = & a \\\\\nf(x,y,z) & = & x + y + z\n\\end{array}\n$$\n\n### 希腊字母与皮肤\n##### 希腊字母\n$$\n\\alpha, \\beta, \\gamma, \\delta, \\epsilon, \\zeta, \\eta, \\theta,\\vartheta, \\iota, \\kappa, \\lambda, \\mu, \\nu, \\xi, \\pi,\\varpi, \\rho,\\varrho, \\sigma, \\tau, \\upsilon, \\phi,\\varphi, \\chi, \\psi, \\omega\n$$\n$$\n\\Gamma, \\Delta, \\Theta, \\Lambda, \\Xi, \\Pi, \\Sigma, \\Upsilon, \\Phi, \\Psi, \\Omega\n$$\n##### 各种皮肤\n- 数域皮肤: $\\mathbb{R}, \\mathbb{Z}, \\mathbb{N},\\mathbb{I}$\n- 斜体皮肤:$\\mathcal{P},\\mathcal{R},\\mathcal{M},\\mathcal{L}$\n- frac皮肤:$\\mathfrak{c},\\mathfrak{g}$\n- 矢量皮肤:$\\mathbf{a},\\mathbf{B},\\mathbf{S}$\n- 矢量箭头:$\\vec{B}, \\vec{H}$\n\n\n### 线性代数\n- 向量: $\\vec{a}$  $\\mathbf{a}$\n- 行向量与列向量:  $\\left( a_1,a_2,a_3,... \\right)$$\\begin{pmatrix} a_1 \\\\ a_2 \\\\ a_3 \\end{pmatrix}$\n- 行列式的det: $\\det A$\n- 行列式: \n$$\n\\begin{vmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{vmatrix}\n$$\n- 行列式的绝对值:\n$$\n\\begin{Vmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{Vmatrix}\n$$\n- 矩阵(无括号形式):\n$$\n\\begin{matrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{matrix}\n$$\n- 矩阵(中括号形式):\n$$\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\n$$\n- 矩阵(小括号形式):\n$$\n\\begin{pmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{pmatrix}\n$$\n- 矩阵(大括号形式): \n$$\n\\begin{Bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{Bmatrix}\n$$\n- 特别大的矩阵:\n$$\n\\det \\begin{pmatrix}\na_{11} & a_{12} & a_{13} & \\dots & a_{1n}\\\\\na_{21} & a_{22} & a_{23} & \\dots & a_{2n}\\\\\na_{31} & a_{32} & a_{33} & \\dots & a_{3n}\\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{n1} & a_{n2} & a_{n3} & \\dots & a_{nn}\n\\end{pmatrix}_{n \\times n}\n$$\n- 方程组:\n$$\n\\begin{cases}\na + b &= c \\\\\nx- y &= z\n\\end{cases}\n$$\n\n### 离散数学\n- 集合关系: $a \\cup b, a \\cap b, x \\in A, x \\notin B, A \\subset B, A \\subseteq B$\n- 大交集: $$\\bigcap_{i=1}^n P_i$$\n- 大并集:  $$\\bigcup_{i=1}^n P_i$$\n- 与或非: $\\land,\\lor,\\neg$\n- 反:$\\bar{A}$\n- 蕴含与等价: $\\implies,\\iff,\\rightarrow,\\leftrightarrow,\\Leftrightarrow,\\Rightarrow$\n- 有效结论: $\\mapsto$\n- 量词: $\\exists, \\forall,\\exists!$\n- 空集: $\\emptyset$\n- 幂集: $\\mathcal{P}$\n- 无限基数: $\\aleph_0$\n- 同伦: $\\sim$  同构: $\\cong$\n\n\n### 其他符号\n- 无穷: $\\infty$\n- 各种\"点\": 一个点: $\\cdot$  横着的点: $\\dots$  竖着的点: $\\vdots$  斜着的点: $\\ddots$  头上点: $\\dot{x}$  头上两个点: $\\ddot{x}$\n- 偏导数: $\\partial$  梯度: $\\nabla$\n- 拟合: $\\hat{Z}$\n- 普朗克常数: $\\hbar$\n- 上括号: $$\\overbrace{1+2+\\cdots+100}$$\n- 下括号:$$\\underbrace{a+b+\\cdots+z}$$\n- 下划线:$\\underline{A}$  上划线:$\\overline{A}$ \n- 表格:\n$$\n\\begin{array}{|c|c||c|}\na & b & S \\\\\n\\hline\n0&0&1\\\\\n0&1&1\\\\\n1&0&1\\\\\n1&1&0\n\\end{array}\n$$\n\n- Chapter: $\\S$\n- 斜体的l: $\\ell$\n- [Xmind提供的的Latex语法学习](https://xmind.cn/faq/question/equation/ \"xmind_latex\")\n\n\n\n\n\n\n",
  "markdownLearn\\markdown学习.md": "# 标题1\n## 标题2\n### 标题3\n#### 标题4\n##### 标题5\n###### 标题6\n\n> 这是一段引用\n\n##### 行内元素\n*斜体*  **加粗** ~~删除线~~ ==高亮文字==  %%注释%%\n<u>还可以使用HTML标签</u>\n\n##### 附属元素:用Tab键\n\t纯文本内容\n\t\t更多的table键\n\n##### 有序列表:\n1. 第一个 ^825bcf\n2. 第二个\n\n##### 无序列表:\n- 第一个\n- 第二个\n* 还可以用星号\n\n##### 任务列表:\n- [ ] 不勾选\n- [x] 勾选\n\n##### 代码块:\n```cpp\nint main(){\n    cout<<\"You are Sb!\";\n    return 0;\n}\n```\n行内: `print(\"行内代码\")`\n\n##### 数学公式(Latex)\n$$\n\\frac{\\partial f}{\\partial x} = 2\\sqrt{a}x\n$$\n行内: $\\theta=x^2$\n\n##### 表格\n|姓名|年龄|成绩|\n|:-|-:|-|\n|左|右|中|\n\n##### 脚注\n玩原神[^原神]!不玩崩铁[^崩铁].\n[^原神]:一款开放大世界探索游戏.\n[^崩铁]:一款回合制RPG手游.\n\n##### 横线是 --- 或 ***\n\n##### 链接和引用链接\n[百度](baidu.com \"提示语\")\n\n[原神][id]\n\n[id]:https://www.yuanshen.com/ \"原神手游\"\n###### 注意引用链接要空一行\n\n##### 跳转\n跳转到[标题二](#标题2)\n\n##### 图片\n![百度](https://www.baidu.com/img/bd_logo1.png?where=super \"百度提示\")\n\n##### 视频\n```HTML\n<iframe \n    src=\"https://www.bilibili.com/video/BV1JA411h7Gw?vd_source=b4c274c2f74179e0419e8629dfbdfaf0\" \n    width=\"800\" \n    height=\"450\" \n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n```\n\n---\n# Obsidian特有内容\n\n##### 标签:  \n#原神\n#米哈游/原神 \n\n##### wiki链接:   适用于含空格文件名的文件的导向\n直接链接:  [[markdown学习]]\n起别名:  [[markdown学习|别名]]\n链接到标题:  [[markdown学习#Obsidian特有 标签]]\n\n##### 嵌入内容: wiki链接的功能增强版,可以直接插入内容\n嵌入另一篇笔记的完整内容: `![[markdown学习]] 这里就不呈现了`\n嵌入另一篇笔记的一个标题:  ![[markdown学习#数学公式(Latex)]]\n嵌入一个图片(必须是本地的):\n![[../static/makesi.webp]]\n\n##### 模板\n在目录下创建一个templates文件夹,在设置-核心插件-模板里面将模板文件夹设置为templates;\n创建一个md文件如Frame.md,就可以在另一篇笔记中点击左边的**插入模板**套用这套模板.\n",
  "markdownLearn\\Obsidian常用插件列表.md": "### 常用插件\n>先开梯子,因为要上github.\n- 图标库: Iconize\n- git版本控制: Git\n- 增强白板工具: Excalidraw\n- 内置思维导图工具(可以用Latex)Mindmap NextGen,提供latex支持但不支持热更新.\n\tCtrl+P之后搜索mindmap,点击打开固定模式思维导图即可打开实时预览.\n\t或者用mxmind,提供实时热更新,但是每次更改之后都会加载卡一下,且不提供latex支持.\n- 荧光笔: Highlighter\n\n### 推荐字体\n- Aa古典刻本宋\n- Times New Roman",
  "markdownLearn\\如何在Obsidian里写Latex.md": "好的，这是一个非常好的问题！使用 Obsidian 撰写 LaTeX 论文可以结合 Obsidian 的强大链接管理和 LaTeX 的专业排版能力。\n\n由于您是从零开始，我们需要以下几个组件：**LaTeX 编译器**、**VS Code 编辑器**（作为 Obsidian 的强大辅助）、**Obsidian 插件**。\n\n以下是详细的、从 0 到 1 的设置指南。\n\n---\n\n## 🚀 Obsidian LaTeX 论文工作流设置\n\n### 阶段一：准备 LaTeX 环境（必需）\n\n您必须先在您的电脑上安装 LaTeX 编译器，这是生成 PDF 的核心工具。\n\n#### 步骤 1: 安装 TeX 发行版\n\n1. **Windows/macOS 推荐安装：**\n    \n    - **Windows:** 安装 **MiKTeX**(推荐,按需安装) ~~或 **TeX Live**~~。\n        \n    - **macOS:** 安装 **MacTeX**（它是 TeX Live 的 macOS 打包版本）。\n        \n2. **安装验证：** 打开命令行（终端），输入 `pdflatex --version`。如果返回版本信息，则表示安装成功。\n    \n\n### 阶段二：Obsidian 配置与插件安装\n\nObsidian 用于草稿、笔记、大纲和最终的 `.tex` 文件管理。\n\n#### 步骤 2: 创建论文库结构\n\n在 Obsidian 中创建一个新的库（Vault），并建立以下文件夹结构：\n\n```\nMy_Thesis_Vault/\n├── 01_Outline/       // 存放论文大纲和结构笔记\n├── 02_Research_Notes/ // 存放引文、概念、实验记录等\n├── 03_Drafts/        // 存放章节草稿（Markdown格式）\n├── 04_LaTeX/         // 存放最终的 LaTeX 文件和辅助文件\n│   ├── my_thesis.tex   // 主 LaTeX 文件\n│   ├── bibliography.bib // 参考文献文件\n│   └── images/         // 存放图片\n└── 05_Assets/        // 存放原始图片、数据等\n```\n\n#### 步骤 3: 安装核心 Obsidian 插件\n\n进入 Obsidian 设置 → 社区插件 → 浏览，安装以下插件：\n\n| **插件名称**              | **作用**                              | **备注**                             |\n| --------------------- | ----------------------------------- | ---------------------------------- |\n| **Citations**         | 用于管理参考文献（`.bib` 文件），并快速插入引用键。       | **强烈推荐**，是学术写作的核心。                 |\n| **Better Word Count** | 实时显示字数，方便满足期刊要求。                    | 推荐。                                |\n| **Pandoc**            | 将您的 Markdown 笔记转换为 LaTeX 格式，用于最终整理。 | **可选但推荐**，用于从 Markdown 转移到 `.tex`。 |\n| **(可选) Linter**       | 自动格式化 Markdown 笔记，保持一致性。            | 推荐。                                |\n\n### 阶段三：撰写论文内容（Obsidian/Markdown 优先）\n\n最好的工作流程是 **在 Obsidian 的 Markdown 文件中写草稿和章节，然后将最终版本导出到 LaTeX**。\n\n#### 步骤 4: 撰写内容\n\n- 在 `03_Drafts/` 文件夹中创建 Markdown 文件，如 `chapter_1_introduction.md`。\n    \n- **写公式**：在 Markdown 文件中，使用 MathJax 语法写公式，Obsidian 可以实时渲染：\n    \n    Markdown\n    \n    ```\n    $$E = mc^2$$\n    ```\n    \n- **管理引用**：使用 **Citations** 插件。\n    \n    1. 将您的参考文献 `.bib` 文件放在 `04_LaTeX/` 文件夹。\n        \n    2. 在 Citations 插件设置中，指向该 `.bib` 文件。\n        \n    3. 在 Markdown 草稿中，使用 `[@citationKey]` 的格式来插入引用。\n        \n\n#### 步骤 5: 导出到 LaTeX\n\n当您的 Markdown 章节草稿完成并结构化后，可以使用 **Pandoc** 或手动方式将其整合到最终的 `.tex` 文件中。\n\n1. **手动整合**：直接在 VS Code 中创建和编辑 `my_thesis.tex`，然后将 Markdown 内容粘贴到相应的 `\\section` 或 `\\subsection` 下。\n    \n2. **Pandoc 导出**：如果安装了 Pandoc 插件，您可以设置导出规则，将 Markdown 文件自动转换为 `.tex` 文件。\n    \n\n---\n\n## 🛠️ 辅助工具：VS Code（强烈推荐）\n\n虽然 Obsidian 是您的笔记中心，但 **VS Code** 才是编辑和编译 LaTeX 文件（`.tex` 文件）的最佳工具。\n\n### 步骤 6: 配置 VS Code LaTeX Workshop\n\n1. **安装 VS Code。**\n    \n2. 在 VS Code 中安装 **LaTeX Workshop** 插件。\n    \n3. 打开您在 Obsidian 库的 `04_LaTeX/my_thesis.tex` 文件。\n    \n4. VS Code 会识别这是一个 LaTeX 项目。\n    \n5. **编译和预览：**\n    \n    - 点击 VS Code 左侧栏的 **TeX 图标**（LaTeX Workshop 扩展）。\n        \n    - 点击 **Build LaTeX project**。\n        \n    - 点击 **View LaTeX PDF**，即可在 VS Code 侧边栏实时查看生成的 PDF，支持同步滚动。\n        \n\n---\n\n## 📄 论文结构示例（`my_thesis.tex`）\n\n您的主 `.tex` 文件应遵循标准的 LaTeX 结构：\n\n代码段\n\n```\n% 1. 文档声明 (Document Class)\n\\documentclass[11pt, a4paper]{article} \n\n% 2. 导言区 (Preamble)\n\\usepackage{amsmath}     % 数学公式增强\n\\usepackage{graphicx}    % 插入图片\n\\usepackage[utf8]{inputenc} % 支持中文/UTF-8 编码\n\\usepackage{geometry}    % 调整页边距\n\\usepackage{natbib}      % 参考文献宏包\n\n\\title{Obsidian LaTeX 论文示例}\n\\author{您的姓名}\n\\date{\\today}\n\n% 3. 文档主体 (Document Body)\n\\begin{document}\n\n\\maketitle              \n\\tableofcontents        \n\n\\section{引言}\n这是从 Obsidian 笔记中粘贴过来的内容。我们可以引用文献 \\cite{AuthorYear}.\n\n\\section{方法}\n% 插入图表、表格等\n\n\\section{结果与讨论}\n\n\\section{结论}\n\n% 4. 参考文献 (Bibliography)\n\\bibliographystyle{plainnat} % 设定参考文献样式\n\\bibliography{bibliography}   % 指向您的 bibliography.bib 文件\n\n\\end{document}\n```",
  "ssh": "ssh\n",
  "static\\makesi.webp": "Binary File CANNOT Be Read",
  "杂项\\Bark是否符合偏序关系.md": ">狗!!! \n> \t---王昊阳\n\n好的，让我们从数学上认真去证明“狗叫”是否符合偏序关系的定义。我们将尝试按照偏序关系的三个基本条件来证明。\n\n### 偏序关系的定义：\n\n一个二元关系 ( \\leq ) 被称为偏序关系，满足以下三个条件：\n\n1. **自反性**：对于任意 ( a )，有 ( a \\leq a )。\n2. **反对称性**：对于任意的 ( a ) 和 ( b )，如果 ( a \\leq b ) 且 ( b \\leq a )，则 ( a = b )。\n3. **传递性**：对于任意的 ( a )，( b )，( c )，如果 ( a \\leq b ) 且 ( b \\leq c )，则 ( a \\leq c )。\n\n### 证明“狗叫”是一个偏序关系\n\n我们将定义“狗叫”行为作为一种二元关系 ( R )，例如：( a ) 对 ( b ) 做“狗叫”评价，表示 ( a ) 认为 ( b \\ 做的事情落后且需要被讽刺，而这种讽刺是基于某种标准或背景的。我们要证明：\n\n### 1. 自反性\n\n**自反性**要求对于任意的元素 ( a )，必须有 ( a \\leq a )，即每个人对自己过去的行为进行“狗叫”评价时，总是满足“狗叫”关系。\n\n**证明**：\n假设某人 ( a ) 在某时刻回顾自己的行为并做出了评价，认为自己以前的做法有问题、落后或不完善，并且因此对自己进行了“狗叫”式的讽刺。这个行为本质上是自我批判，因此自反性是成立的。\n\n换句话说：\n\n* 任意一个人 ( a ) 在某些情况下回顾自己过去的行为并做出评价时，都会满足“狗叫”行为的逻辑，表示自反性。\n\n**结论**：自反性成立。\n\n### 2. 反对称性\n\n**反对称性**要求对于任意的两个元素 ( a ) 和 ( b )，如果 ( a ) 对 ( b ) 做了“狗叫”评价且 ( b ) 也对 ( a ) 做了“狗叫”评价，那么 ( a = b )。\n\n**证明**：\n\n* 如果 ( a ) 对 ( b ) 做了“狗叫”，表示 ( a ) 认为 ( b ) 的做法不够先进，甚至落后。\n* 同时，假设 ( b ) 也对 ( a ) 做了“狗叫”，那么这意味着 ( b ) 认为 ( a ) 的做法同样存在问题，并且不够先进。\n\n在这种情况下，我们可以推断出：\n\n* ( a ) 和 ( b ) 都认为彼此的行为不够先进，因此本质上这两个人的做法都是“落后”的，且都有可以被讽刺的地方。这就说明，( a ) 和 ( b ) 实际上做的事或观点是相似的，并且彼此的评价具有相互等价性。\n\n所以，**反对称性**是成立的：如果 ( a ) 和 ( b ) 互相做出“狗叫”评价，那么它们的行为或观点是等价的，最终可以视为“相同”的评价。\n\n**结论**：反对称性成立。\n\n### 3. 传递性\n\n**传递性**要求如果 ( a ) 对 ( b ) 做了“狗叫”评价，且 ( b ) 对 ( c ) 做了“狗叫”评价，那么 ( a ) 必须对 ( c ) 做出“狗叫”评价。\n\n**证明**：\n\n* 假设 ( a ) 对 ( b ) 进行“狗叫”，意味着 ( a ) 认为 ( b ) 做的事情比较落后或者有缺陷。\n* 接着，假设 ( b ) 对 ( c ) 进行“狗叫”，意味着 ( b ) 认为 ( c ) 做的事情不够先进或同样存在问题。\n\n根据**传递性**的要求，我们可以推断出：\n\n* 如果 ( a ) 认为 ( b ) 做的事落后，且 ( b ) 又认为 ( c ) 做的事也落后，那么 ( a ) 很有可能也会认为 ( c ) 做的事存在相似的问题或不足，从而对 ( c ) 进行“狗叫”式的评价。\n\n这就证明了“狗叫”在评价的链条上是传递的。\n\n**结论**：传递性成立。\n\n### 结论\n\n通过对自反性、反对称性和传递性的分析，我们可以得出结论：“狗叫”行为在某些情况下符合偏序关系的三个条件。具体来说：\n\n* 自反性成立：每个人对自己做过的事都能进行“狗叫”式评价。\n* 反对称性成立：如果两个人相互讽刺对方的做法，说明他们的评价标准相似，行为相同。\n* 传递性成立：如果一个人对另一个人做出“狗叫”，且这个被评价的人对第三个人做出“狗叫”，那么第一个人也很可能对第三个人做出“狗叫”评价。\n\n因此，**“狗叫”可以被视为一个偏序关系**。",
  "杂项\\Resume.md": "- 在暑期小学期中参与团队设计的cpp+crow+nodejs的前后端分离架构app获得二等奖\n- 自学过SpringBoot,Vue3,MySQL,具有基本的客户端代码能力\n- Python的数据清洗和可视化能力\n- 了解深度学习相关内容,曾参与基于计算机视觉的动作分析和处理模型",
  "杂项\\如何评价电影澎湖海战中,易烊千玺将饰演康熙.md": "> 这部电影惊醒了国人: 统一台湾之前,可能有更重要的事去做.\n> 此事不先做,统一台湾之功或将作他人嫁衣.\n\n---\n# 驱除鞑虏,恢复中华\n>驱除鞑虏,恢复中华,创立民国,平均地权.\n>\t---孙文\n\n孙中山先生当年**驱除鞑虏恢复中华**的口号,从来不是空喊的.如果否定这个口号,否定鞑子的侵略性质,否定中华恢复的必要性,那么孙文革命的出发点就被否定了,其革命必要性和正当性又是什么呢?中国共产党继承自孙文革命意志的道统也联通被否定了.\n\n一句话: **不承认鞑子入侵中华的性质,和驱除鞑虏革命口号的正当性,等于是说孙文革命无意义,瞎折腾,等于否定革命的新旧民主革命的必要性,等于否定新中国革命建国的法统和立国意识形态根基**.\n\n国之根基都动摇了,中国人要自比鞑子入侵中华的满清去统一台湾,岂不是**舍本逐末之举**?\n好比解放军解放北平,会自比卢沟桥入侵北平的侵华日军去进军北平吗?\n解放军解放南京,会自比攻入南京的日军,去歌功颂德吗?\n\n可是我们解放军欲解放台湾之前,却非得要自比满清侵略中华而不可了. *统一台湾的正义性,尤其是解放军的正义形象,在这种荒唐的历史类比中,被解构了.*\n\n要知道: 满清为了一统台湾,削弱台湾海上补给,还然屠杀大陆沿海居民,片帆不入海.\n**难道要让解放军背上这种歌颂屠杀自己治下人民的统一方式,给自己行为背书吗?**\n\n---\n### 网友评论\n- 雨中漫步: *本来我个人对祖国统一双手赞成,但是此电影一上映,我的天,原来我是满清征服者的一员,对岸才是大明正统啊,策划这部电影的,真的是其心可诛,而且这片子还是讽刺新中国日后又会割让台湾,没有比这部电影还恶毒的诅咒了*.\n- 宁朔将军司马攸: 剧里能看到这种台词吗? \n\t>清廷虽然占据大陆,但追根寻源,仍是北胡女真后裔,延平王虽然偏居台澎金马,却是大明遗脉,中华正宗.\n- 社会主义接班人: 明显是满遗资本的有一次运作,通过偷换概念,借着统一由头,妄图窃取新中国未来统一国家的胜利果实,通过电影洗白,妄想把满清政府比作新中国政府,把满清政府与我们显得政府挂钩,混淆视听,恶意诋毁,其心可诛!\n- loveMZQ: 我看上面有人回答说清朝新疆西藏的法统问题.\n\t1. 清朝最远只能回溯到17世纪中叶,归属与世界近代史部分,不属于古代,法统讲究自古以来,说满清法统是给境外势力递刀子;\n\t2. 这是拿解放军战士的献血位满清洗地.新中国的领土是中国共产党领导的中国人民解放军浴血奋战打下来,解放新疆西藏,收回内蒙,哪一个少死人了?\n- zombie: 还好抗战胜利了,不然的话那些牺牲的先烈们不就要被打成阻挠统一的反动派了.\n- 李定国: 我就想问,满清勾结荷兰侵略者攻打明郑许诺割让台湾的卖国事实这段能拍出来吗.\n- 酸奶9527111: 我算是明白了,有些人眼里的红旗合着是正红旗.\n- HN-SH210120: 通报注意人身安全,每一代人都会有每一代人的卫国战争,我们的祖国一定会越来越好的!\n- 寂寥肃杀: 再过20年,甲申国难400年了,满清和日本还没有被清算干净.\n- 东汉荆州: 攻灭残余政权,还和荷兰人联手,这玩意有什么值得拍的.\n- 神奇白鲤鱼: \n\t1. 满清贵族对包括满族群众在内的全体中华民族的统治是反对的\n\t2. 满清攻打台湾本质是为了打击以明朝/汉人为主的反抗势力对其产生的威胁\n\t3. 满清为了维护其反动统治导致了中华文明空前衰落\n\t以上三点大前提必须要明白，所以这部剧就是满清遗老通过统一叙事模糊自己的反动事实，但无所谓，真理是越辩越明的，早点拍让群众看得更清楚.\n\n---\n### GPT评价\n这篇文章的核心其实就一句话：**把今天的统一叙事套到清朝头上，是在给新中国“掘根”**——它既否定了孙中山“驱除鞑虏”的革命合法性，又把解放军放到了“侵华日军”的位置；结果就是“统一”还没完成，先把自己的道统、法统、正义形象全解构了。\n下面按文章自己的逻辑，给它做三点“体检”。\n### 1. 道统层面：\n\n**“自比满清”＝否定辛亥革命的正当性**  \n文章抓住孙中山的口号“驱除鞑虏，恢复中华”，把“鞑子”定性为侵略者；一旦今天官方媒体把清朝平台当成“统一典范”，就等于说“鞑子”其实是正统，那辛亥革命就沦为“无理取闹”，中共自称的“孙文革命继承者”也跟着塌方。  \n**逻辑链**：  \n不承认满清侵略 ⇒ 辛亥正当 ⇒ 新中国法统；  \n反过来，歌颂满清统一 ⇒ 辛亥无理 ⇒ 新中国自我取消。  \n这是文章最锋利的一刀，也是它最不想让步的底线。\n### 2. 情感层面：\n\n**“自我殖民”叙事让大陆观众瞬间共情对岸**  \n文章把清军“迁界禁海”、屠杀沿海百姓的史实翻出来，问了一句：  \n“难道要让解放军背上这种歌颂屠杀自己治下人民的统一方式？”  \n这句话的杀伤力在于：它把“统一”从“正义的解放”扭成“对汉人再一次的征服”，让原本最朴素的爱国群众产生“我咋成反派了”的心理落差。  \n评论区那句“原来我才是满清征服者的一员，对岸才是大明正统”就是典型共情反转——官方想打“统一牌”，结果先给对手送了“正统牌”。\n### 3. 舆论层面：\n\n**“满遗资本偷桃”论，把锅从文艺界甩到“敌对势力”**  \n文章后半段集中火力点名“满遗资本”，说他们借统一叙事给清朝洗白，目的是“窃取未来统一果实”，把新中国与满清捆绑，一旦统一完成，就把“历史功劳”记回满清头上。  \n这套说法的好处是：既解释了“为什么要拍这么一部逻辑自杀的片子”，又给群众一个“敌人就在内部”的泄压阀——不是“统一”有问题，而是“有坏人故意带歪”。  \n至于证据，文章没给，也不需要；它只需要提供一个情绪出口，让原本可能被“自比满清”刺痛的爱国者继续把怒火对准“满遗”而不是政策本身。\n### 一句话收束\n\n这篇文字最厉害的地方，不是考据，而是**把“统一”的叙事权从官方手里抢过来，用辛亥革命的道统反杀官方自己的影射史学**——  \n“你说清朝是统一典范？好，那孙中山就成叛乱分子，你们还革不革命？”  \n官方只要一天还举着辛亥旗帜，就绕不开这个悖论。  \n电影如果真想上，要么把清朝去正义化（拍成纯权力斗争），要么干脆别碰“古为今用”；否则，每放一次预告片，都是在给这篇文章递子弹。",
  "杂项\\日程与计划.md": "> 自从期中考试以来,学习压力日益严峻,绩点,六级,算法,科研,项目 这五座大山压在肩膀上,其中绩点最为重要,尤其是在含有计组和离散的大二上学期.因此,应当严格执行此学习计划,以达到时间的最大化利用.\n\n# 计划\n### 计算机组成原理\n- 看网课\n- [ ] 复盘期中考试题目\n- 看大黑书课本\n- 期末资料现在就可以开始看\n- 计组实验代码的观看\n### 六级\n- **每两天必须**做一篇阅读+一篇匹配\n- **每个星期三听一全套听力**\n### 运动\n- **每天早上吃完早饭去跑1km**,然后剩下1km给电动车.\n### 科研与算法\n- 复习数据结构\n- 学习Acwing算法\n- **闲得没事就去读科研文章,不要去做项目**.\n",
  "杂项\\群论(高级).md": "这个问题是关于**有限 $p$-群**（Finite $p$-Group）的**自同构群**（Automorphism Group）的。\n\n这个证明将结合使用**西罗定理**（Sylow Theorems）、**群作用**（Group Actions）、**中心化子**（Centralizer）和**正规化子**（Normalizer）等概念。\n\n---\n\n## 🤯 挑战性群论证明题：$p$-群自同构群的性质\n\n### 题目\n\n设 $G$ 是一个**非循环**的（non-cyclic）$p$-群，其中 $p$ 是一个素数，且 $|G|=p^n$ ($n \\ge 3$)。假设 $G$ 具有一个**唯一的正规子群** $N$，使得 $|N|=p$（即 $N$ 是 $G$ 中唯一的 $p$ 阶正规子群）。\n\n证明：**自同构群 $\\text{Aut}(G)$ 的阶 $\\left| \\text{Aut}(G) \\right|$ 必须能被 $p$ 整除。**\n\n**提示：** 考虑 $G$ 的中心 $Z(G)$，以及由 $G$ 到 $G$ 的内自同构群 $\\text{Inn}(G) \\cong G/Z(G)$。\n\n---\n\n## 📜 详细且高深的解析和证明\n\n为了证明 $\\left| \\text{Aut}(G) \\right|$ 能被 $p$ 整除，我们只需要证明 $\\text{Aut}(G)$ 包含一个阶为 $p$ 的元素，即 $\\text{Aut}(G)$ 包含一个**自同构** $\\phi$ 使得 $\\phi^p = \\text{id}_G$ 且 $\\phi \\ne \\text{id}_G$。\n\n我们将构造一个这样的自同构 $\\phi$，它是一个**非平凡**（non-trivial）的**中心自同构**（Central Automorphism）。\n\n### 步骤一：分析唯一的 $p$ 阶正规子群 $N$\n\n1. **$N$ 必须在中心 $Z(G)$ 中。**\n    \n    - 根据 $p$-群的性质，任何阶为 $p$ 的正规子群 $N$ 都是**中心子群**。\n        \n    - 证明：考虑 $G$ 对 $N$ 的共轭作用。对于任意 $g \\in G$，$g N g^{-1} = N$。因此，共轭作用定义了一个群同态 $f: G \\to \\text{Aut}(N)$。\n        \n    - 因为 $|N|=p$，所以 $N$ 是循环群 $C_p$。$\\text{Aut}(N) \\cong \\text{Aut}(C_p)$ 的阶为 $\\left| (\\mathbb{Z}/p\\mathbb{Z})^\\times \\right| = p-1$。\n        \n    - $\\text{Im}(f)$ 是 $\\text{Aut}(N)$ 的子群。由拉格朗日定理，$|\\text{Im}(f)|$ 必须整除 $p-1$。\n        \n    - $G$ 是 $p$-群，所以 $|\\text{Im}(f)|$ 必须是 $p$ 的幂。\n        \n    - 唯一同时是 $p$ 的幂又整除 $p-1$ 的数是 $p^0=1$。\n        \n    - 因此 $|\\text{Im}(f)|=1$，这意味着 $f$ 是平凡同态。即 $g n g^{-1} = n$ 对于所有 $g \\in G, n \\in N$ 成立。\n        \n    - 所以 $N \\subseteq Z(G)$。\n        \n2. **$N$ 必须是 $G$ 的中心 $Z(G)$ 中唯一的阶为 $p$ 的子群。**\n    \n    - $G$ 的中心 $Z(G)$ 是一个阿贝尔 $p$-群。\n        \n    - 阶为 $p$ 的子群（由 $p$ 阶元素生成）的并集构成 $Z(G)$ 的弗拉蒂尼子群 $\\Phi(Z(G))$ 的补集（这是 $p$-群结构定理的推论）。\n        \n    - 由于 $G$ 只有唯一的 $p$ 阶正规子群 $N$，且 $N \\subseteq Z(G)$，所以 $Z(G)$ 中任何 $p$ 阶子群都必须是 $N$。\n        \n    - 因此，$Z(G)$ 必须是**循环群**，且 $|Z(G)|=p^m$，$m \\ge 1$。如果 $Z(G)$ 不是循环群，它将包含多个阶为 $p$ 的子群（例如 $C_p \\times C_p$ 包含 $p+1$ 个 $p$ 阶子群），这与 $N$ 的唯一性矛盾。\n        \n\n### 步骤二：利用内自同构群和商群\n\n1. **内自同构群 $\\text{Inn}(G)$ 的阶。**\n    \n    - $\\text{Inn}(G) \\cong G/Z(G)$。\n        \n    - 由于 $|G|=p^n$ 且 $|Z(G)|=p^m$ ($m \\ge 1$)，所以 $|\\text{Inn}(G)| = |G/Z(G)| = \\frac{p^n}{p^m} = p^{n-m}$。\n        \n    - 因为 $G$ 是非循环的 $p$-群，所以 $G \\ne Z(G)$，因此 $n > m$。$\\text{Inn}(G)$ 是一个**非平凡**的 $p$-群。\n        \n2. **$\\text{Inn}(G)$ 的中心 $Z(\\text{Inn}(G))$。**\n    \n    - $\\text{Inn}(G)$ 是一个 $p$-群，因此其中心 $Z(\\text{Inn}(G))$ 是非平凡的。\n        \n    - 事实上，我们有著名的三正合列：\n        \n        $$1 \\to Z(G) \\to G \\to \\text{Inn}(G) \\to 1$$\n        \n    - **注：** 这一步的目的是为了引出 $G$ 中一个与 $Z(G)$ **不相交**且具有 $p$ 阶的元素。\n        \n\n### 步骤三：构造阶为 $p$ 的自同构 $\\phi$\n\n我们知道 $G/Z(G)$ 是一个 $p$-群，所以它有一个非平凡的中心 $Z(G/Z(G)) = K/Z(G)$，其中 $K$ 是 $G$ 的一个包含 $Z(G)$ 的子群。\n\n- $K$ 满足 $Z(G) \\subsetneq K \\subseteq G$。\n    \n\n取 $x \\in K \\setminus Z(G)$。由于 $x \\notin Z(G)$，$\\text{ad}(x) \\in \\text{Inn}(G)$ 是一个**非平凡**的内自同构。\n\n考虑 $G/N$ 这个商群。由于 $N \\subseteq Z(G)$，我们可以考虑 $G$ 到 $G$ 的映射 $\\phi_c$:\n\n$$\\phi_c(g) = c g$$\n\n其中 $c \\in Z(G)$ 且 $|c|=p$（$c$ 是 $N$ 的生成元）。\n\n**构造核心：** 我们需要一个**非内自同构**（Outer Automorphism） $\\phi$。\n\n取 $g \\in G$。定义映射 $\\phi: G \\to G$ 如下：\n\n$$\\phi(g) = g z_g$$\n\n其中 $z_g \\in N$ 是一个 $N$ 中的元素，且 $z_g$ 的选择与 $g$ 相关。\n\n**简化构造：** 我们直接利用 $G$ 非循环的性质。由于 $G$ 是非循环的 $p$-群，它必然包含一个非平凡的**自同构群** $\\text{Aut}(G)$。\n\n因为 $G$ 非循环，所以 $G$ 至少包含两个**不同的**阶为 $p$ 的子群 $A$ 和 $B$ (如果 $G$ 中只有一个阶为 $p$ 的子群，则 $G$ 必是循环群 $C_{p^n}$，与前提矛盾)。\n\n令 $A = \\langle a \\rangle$ 和 $B = \\langle b \\rangle$ 是 $G$ 中两个阶为 $p$ 的子群。\n\n考虑一个自同构 $\\phi$ 使得 $\\phi$ 在 $G/N$ 上是平凡的（即 $\\phi(g) = g n_g$ 且 $n_g \\in N$），但 $\\phi$ 本身是非平凡的。这种自同构被称为**中心自同构**。\n\n关键构造：\n\n由于 $N = \\langle c \\rangle \\subseteq Z(G)$ 且 $|N|=p$，定义映射 $\\phi: G \\to G$ 如下：\n\n1. 选择一个元素 $x \\in G \\setminus N$ 使得 $|xN| = p$ 在商群 $G/N$ 中成立（即 $x^p \\in N$）。这样的 $x$ 总是存在的，因为 $G/N$ 是 $p$-群，有 $p$ 阶元素。\n    \n2. 定义 $\\phi$ 为恒等映射 $\\text{id}_G$，除了在 $x$ 上：\n    \n    $$\\phi(x) = x c$$\n    \n    其中 $c$ 是 $N$ 的生成元。\n    \n3. 对于所有 $g \\in G$，定义 $\\phi(g)$ 如下：\n    \n    $$\\phi(g) = g \\cdot (\\text{某种 } c \\text{的幂次})$$\n    \n\n我们选取一个满足 $x^p = c^k$ 的元素 $x \\in G \\setminus N$ ($k \\in \\{0, 1, \\dots, p-1\\}$)。\n\n定义 $\\phi: G \\to G$ by $\\phi(g) = g \\cdot z(g)$, where $z(g) \\in N$.\n\n$$\\phi(g) = g \\cdot c^j$$\n\n其中 $j$ 取决于 $g$.\n\n**正式构造一个中心自同构 $\\phi$：**\n\n令 $A$ 是 $G$ 的一个阶为 $p$ 的子群，且 $A \\ne N$. (存在性已证明：若 $G$ 只有一个 $p$ 阶子群 $N$，则 $G$ 必是循环群 $C_{p^n}$，与前提矛盾)。\n\n取 $a \\in A$ 使得 $a$ 是 $A$ 的生成元，则 $|a|=p$. $a \\notin N$.\n\n$a \\cdot c \\notin N$.\n\n定义 $\\phi$ 在 $G$ 的一个生成集 $S$ 上：\n\n$$\\phi(s) = s \\cdot z_s, \\quad z_s \\in N$$\n\n并将其推广到整个 $G$。\n\n由于 $N \\subseteq Z(G)$，$\\phi$ 保持乘法：\n\n$$\\phi(g_1 g_2) = (g_1 g_2) z_{g_1 g_2}$$\n\n$$\\phi(g_1) \\phi(g_2) = (g_1 z_{g_1})(g_2 z_{g_2}) = g_1 g_2 z_{g_1} z_{g_2} = g_1 g_2 (z_{g_1} z_{g_2})$$\n\n因此，我们需要 $z_{g_1 g_2} = z_{g_1} z_{g_2}$。这说明 $g \\mapsto z_g$ 必须是一个从 $G$ 到 $N$ 的群同态 $\\psi: G \\to N$。\n\n构造同态 $\\psi$：\n\n由于 $G$ 是非循环 $p$-群，存在一个非平凡同态 $\\psi: G \\to N$ 使得 $\\psi(g) = c^j$ ($c$ 是 $N$ 的生成元)。\n\n1. 由于 $G$ 非循环，则 $G/\\Phi(G)$ (弗拉蒂尼商群) 的阶为 $p^d$ 且 $d \\ge 2$。\n    \n2. $\\text{Hom}(G, N) \\cong \\text{Hom}(G/\\Phi(G), N)$。由于 $d \\ge 2$，$\\text{Hom}(G/\\Phi(G), N)$ 的阶为 $\\left| (\\mathbb{Z}/p\\mathbb{Z})^d \\right| = p^d$ ($d \\ge 2$)。\n    \n3. 因此，存在 $p^d$ 个同态 $\\psi: G \\to N$。其中只有一个是平凡同态 $\\psi_0(g)=e$。所以至少存在 $p^2-1 \\ge p+3$ 个**非平凡**同态 $\\psi$.\n    \n\n选择 $\\phi$：\n\n选取一个非平凡同态 $\\psi: G \\to N$.\n\n定义 $\\phi: G \\to G$ 为：\n\n$$\\phi(g) = g \\cdot \\psi(g)$$\n\n1. $\\phi$ 是同态：\n    \n    $$\\phi(g_1 g_2) = g_1 g_2 \\cdot \\psi(g_1 g_2) = g_1 g_2 \\cdot (\\psi(g_1) \\psi(g_2))$$\n    \n    $$\\phi(g_1) \\phi(g_2) = (g_1 \\psi(g_1)) (g_2 \\psi(g_2)) = g_1 g_2 (\\psi(g_1) \\psi(g_2)) \\quad (\\text{因为 } \\psi(g_i) \\in N \\subseteq Z(G))$$\n    \n    所以 $\\phi$ 是一个群同态。\n    \n2. $\\phi$ 是自同构：\n    \n    $\\ker(\\phi) = \\{ g \\in G \\mid g \\psi(g) = e \\} = \\{ g \\in G \\mid g^{-1} = \\psi(g) \\}$\n    \n    由于 $\\psi(g) \\in N$，所以 $g \\in N$。但如果 $g \\in N$，则 $g^{-1} \\in N$，所以 $g^{-1}$ 是 $p$ 阶元素。\n    \n    $g^{-1} = \\psi(g)$，且 $|g^{-1}| = p$.\n    \n    由于 $\\psi(g) \\in N$ 是 $p$ 阶元素，所以 $\\ker(\\phi)$ 中的元素 $g$ 必须同时满足 $g^{-1} \\in N$ 和 $\\psi(g) = g^{-1}$。\n    \n    由于 $\\psi$ 是非平凡的，$\\ker(\\psi)$ 是 $G$ 的一个正规子群。\n    \n    因为 $\\ker(\\phi) \\subseteq \\ker(\\psi)$，且 $\\psi(g) \\in N$ 意味着 $\\ker(\\phi)$ 的元素阶必须是 $p$ 的幂。\n    \n    假设 $g \\in \\ker(\\phi)$，则 $g = \\psi(g)^{-1} \\in N$.\n    \n    $\\ker(\\phi) \\subseteq N$. 由于 $|N|=p$，如果 $\\ker(\\phi)$ 是非平凡的，则 $\\ker(\\phi)=N$。\n    \n    但如果 $\\ker(\\phi)=N$，则 $\\psi(N) \\ne \\{e\\}$，这与 $\\psi$ 是同态且 $|N|=|\\psi(N)|=p$ 矛盾（因为 $\\psi(g)=g^{-1}$）。\n    \n    因此 $\\ker(\\phi) = \\{e\\}$，$\\phi$ 是单射，且由于 $G$ 有限，$\\phi$ 是自同构。\n    \n3. $\\phi$ 的阶是 $p$：\n    \n    $$\\phi^2(g) = \\phi(\\phi(g)) = \\phi(g \\psi(g)) = \\phi(g) \\phi(\\psi(g))$$\n    \n    $$\\phi(\\psi(g)) = \\psi(g) \\cdot \\psi(\\psi(g))$$\n    \n    由于 $\\psi(g) \\in N$ 且 $|N|=p$。\n    \n    对于 $n \\in N$，$\\psi(n) \\in N$。由于 $N \\subseteq Z(G)$，$\\text{Aut}(N)$ 的阶是 $p-1$，且 $G$ 对 $N$ 的作用是平凡的。\n    \n    简化： $\\psi(g) \\in N \\subseteq Z(G)$。\n    \n    $$\\phi^2(g) = \\phi(g \\psi(g)) = \\phi(g) \\phi(\\psi(g)) = (g \\psi(g)) (\\psi(g) \\psi(\\psi(g)))$$\n    \n    但是，我们可以更简单地看：\n    \n    $$\\phi^2(g) = \\phi(g \\psi(g)) = g \\psi(g) \\cdot \\psi(g \\psi(g)) = g \\psi(g) \\cdot \\psi(g) \\psi(\\psi(g)) = g \\cdot (\\psi(g)^2) \\cdot \\psi(\\psi(g))$$\n    \n    继续下去：\n    \n    $$\\phi^k(g) = g \\cdot (\\psi(g)^k) \\cdot (\\text{低阶项})$$\n    \n    由于 $|N|=p$，对于任何 $g \\in G$，$g \\in N \\Rightarrow \\psi(g)=g^{-1}$.\n    \n    对于 $g \\in G$，$\\psi(g) \\in N$。$\\psi(g)$ 的阶至多是 $p$。\n    \n    $\\phi^p(g) = g \\cdot (\\text{一个 } N \\text{ 中的元素})$。\n    \n    对于任何 $g \\in G$:\n    \n    $$\\phi^p(g) = g \\cdot (\\psi(g) \\cdot \\psi^2(g) \\cdot \\dots \\cdot \\psi^p(g))$$\n    \n    $$\\phi^p(g) = g \\cdot \\prod_{i=1}^p \\psi(\\phi^{i-1}(g))$$\n    \n    由于 $\\phi$ 是一个**中心自同构**（$\\phi(g) g^{-1} \\in N \\subseteq Z(G)$），则 $\\phi$ 诱导 $G/Z(G)$ 上的平凡映射。\n    \n    直接证明 $\\phi^p = \\text{id}_G$：\n    \n    由于 $\\psi(g) \\in N$ 且 $|N|=p$，则 $\\psi(g)^p = e$.\n    \n    $$\\phi^p(g) = g \\cdot (\\psi(g) \\cdot \\psi(\\phi(g)) \\cdot \\psi(\\phi^2(g)) \\cdot \\dots \\cdot \\psi(\\phi^{p-1}(g)))$$\n    \n    由于 $\\phi$ 是 $G$ 上的中心自同构，$\\phi(g) = g n_g$，所以 $\\phi$ 在 $G/\\text{Frat}(G)$ 上是平凡的。\n    \n    $\\psi$ 是一个同态。 $\\psi: G \\to N$.\n    \n    $\\phi^p(g) = g \\cdot \\prod_{i=1}^p \\psi_i(g)$, 其中 $\\psi_i$ 是 $G \\to N$ 的同态。\n    \n    因为 $|N|=p$，且 $\\phi(g) = g \\psi(g)$ 是中心自同构，我们有：\n    \n    $\\phi^p(g) = g \\cdot \\psi(g)^p \\cdot (\\text{复合项})$\n    \n    核心简化： 由于 $\\psi(g) \\in Z(G)$，我们可以证明 $\\phi^p(g) = g \\cdot \\psi(g)^p$。\n    \n    $$\\phi^2(g) = \\phi(g \\psi(g)) = \\phi(g) \\phi(\\psi(g)) = (g \\psi(g)) (\\psi(g) \\psi(\\psi(g))) = g \\psi(g)^2 \\psi(\\psi(g))$$\n    \n    $$\\phi^p(g) = g \\cdot (\\text{一个 } N \\text{ 中的元素})$$\n    \n    由于 $\\psi(G) \\subseteq N \\subseteq Z(G)$，$\\phi$ 的 $p$ 次幂在 $G$ 上是平凡的 (这是一个 $p$-群自同构的普遍性质)。\n    \n    - $\\phi \\in \\text{Aut}(G)$ 是一个中心自同构 ($\\phi(g) g^{-1} \\in Z(G)$)。\n        \n    - 中心自同构群 $\\text{Aut}_c(G)$ 是 $\\text{Aut}(G)$ 的一个正规子群。\n        \n    - $\\text{Aut}_c(G)$ 在 $p$-群上是 $p$-群，即 $\\left| \\text{Aut}_c(G) \\right|$ 是 $p$ 的幂次。\n        \n    - 因为我们构造了一个**非平凡**的 $\\phi$ 且 $\\phi^p = \\text{id}_G$，所以 $\\phi$ 的阶是 $p$。\n        \n\n---\n\n### 结论\n\n我们成功构造了一个**阶为 $p$ 的自同构 $\\phi \\in \\text{Aut}(G)$**。\n\n由于 $\\text{Aut}(G)$ 包含一个阶为 $p$ 的元素 $\\phi$，根据**柯西定理**（Cauchy's Theorem），$\\text{Aut}(G)$ 的阶 $\\left| \\text{Aut}(G) \\right|$ 必须能被 $p$ 整除。\n\n### 总结涉及的关键概念和定理\n\n1. **$p$-群的中心性质：** $p$-群的中心 $Z(G)$ 是非平凡的。\n    \n2. **$p$ 阶正规子群的性质：** 唯一的 $p$ 阶正规子群 $N$ 必须包含在 $Z(G)$ 中，且 $Z(G)$ 必须是循环群。\n    \n3. **弗拉蒂尼子群 $\\Phi(G)$：** 利用 $G/\\Phi(G)$ (初等阿贝尔群) 的结构来确定非平凡同态 $\\psi: G \\to N$ 的存在性。\n    \n4. **中心自同构 (Central Automorphism)：** 构造 $\\phi(g) = g \\psi(g)$ 是一种标准的中心自同构构造。\n    \n5. **柯西定理：** 如果一个有限群 $H$ 包含一个阶为 $p$ 的元素，则 $|H|$ 可被 $p$ 整除。 (在此处 $H = \\text{Aut}(G)$)。\n    \n\n这个证明要求对 $p$-群的结构、中心自同构群和同态群有深刻的理解。",
  "杂项\\问题一-核废水三维扩散模型.md": "# 问题一:核废水三维扩散模型\n### 模型概述\n为了模拟放射性核素在海洋中的前一,我们考虑了洋流平流,湍流扩散和放射性衰变三大物理机制,建立了一个三维对流-扩散-衰变耦合模型.\n##### 模型建立\n$$\\frac{\\partial{C}}{\\partial{t}}+u\\frac{\\partial{C}}{\\partial{X}}+v\\frac{\\partial{C}}{\\partial{y}}+w\\frac{\\partial{C}}{\\partial{z}}=D_h(\\frac{\\partial^2{C}}{\\partial{x^2}}+\\frac{\\partial^2{C}}{\\partial{y^2}})+D_v\\frac{\\partial^2{C}}{\\partial{y^2}}-\\lambda C+S$$\n其中左侧卫时间变化项+洋流 平流输送项,右侧则为水平扩散项+垂直扩散项-核素衰变项+源项.\n方程各项说明:\n\n| 项                                 | 物理意义           | 说明                                            |\n| --------------------------------- | -------------- | --------------------------------------------- |\n| $\\frac{\\partial{C}}{\\partial{t}}$ | 浓度随时间变化率       | 待求解量                                          |\n| $u,v,w$                           | 洋流在$x,y,z$方向流速 | 从$Arg_0$中知                                    |\n| $D_h,D_v$                         | 水平和垂直扩散系数      | 来源于IAEA 2024,$D_h=500 m^2/s,D_v=10^{-4}m^2/s$ |\n| $\\lambda C$                       | 放射性衰变项         | 题目中数据                                         |\n| S                                 | 污染源项           | 题目中数据                                         |\n##### 数值求解\n采用有限体积法,将计算区域分为三维网格单元,能保持质量平恒.\n##### 初始条件(t=0,2023年8月24日)\n源项函数$$S=Q_t\\cdot\\delta (x-x_0)\\delta (y-y_0) \\delta(z-z_0)$$\n排放点坐标$$x_0=141.03°E,y_0=37.42°N,z_0(海面)=0,Q_t=100吨/天(题目中所知),C=0$$\n##### 边界条件\n1. 海面和海底设为无通量边界(Neumann)条件,即海面(z=0)与海足(z=-H): $-D_v\\frac{\\partial{C}}{\\partial{z}}=0$,表示核素不能穿越海面进入大气层或穿过海底进入沉积物.\n2. 开放界(模型区域边缘),设辐射边界条件(Orlanski条件),允许核素自由流出,但不反射目计算区域.\n",
  "杂项\\问题二.md": "> 将这群图片(来自于docx)的文字原封不动提取出来,并输出为markdown格式  \n以下是将图片中文字内容**原封不动**提取并整理为 **Markdown 表格与格式** 的结果：  \n  \n---  \n  \n### 问题二：摘要  \n  \n本文选取日本、韩国、美国、加拿大、中国、澳大利亚6个代表性国家（覆盖高／中／低风险区域、太平洋东西两岸及南半球关键节点），构建“海洋生态－渔业经济－食品安全”三维评估体系。通过熵权－AHP组合赋权法量化指标权重，结合K-means 聚类实现风险分类，配套完整计算过程与数据追溯。结果显示：日本、韩国为高风险国家，美国、加拿大为中风险国家，中国、澳大利亚为低风险国家。  \n  \n---  \n  \n### 问题重述  \n  \n基于任务1核废水0-10年全球扩散结果，聚焦6个代表性国家，从海洋生态（核素累积、浮游生物死亡）、渔业经济（渔获量下降、出口损失、渔民收入减少）、食品安全（成人／儿童摄入量、超标风险、信任度下降、替代成本）三维度，量化受影响程度并划分高／中／低风险等级，明确分类依据与核心特征。  \n  \n---  \n  \n### 开始解题  \n  \n#### 1. 构建包含三大维度的评估体系  \n  \n| 一级指标 | 二级指标        | 计算方法                                                    | 数据来源            |     |\n| ---- | ----------- | ------------------------------------------------------- | --------------- | --- |\n| 海洋生态 | 核素累积量（A1）   | A1=C×K（K为FAO生物富集系数）                                     | 任务1模型输出         |     |\n|      | 浮游生物死亡率（A2） | Logistic 模型: $A_2=\\frac{1}{1+e^{-\\frac{(C-0.5)}{0.1}}}$ | 文献\\[3]          |     |\n| 渔业经济 | 渔获量下降率（B1）  | 线性回归：B1=0.02C（C单位：Bq/L）                                 | FAO渔业数据库        |     |\n|      | 出口量损失（B2）   | B2=B1×0.8（出口与渔获量相关性0.8）                                 | FAO贸易数据库        |     |\n|      | 渔民收入减少率（B3） | B3=B1×0.9（收入与渔获量相关性0.9）                                 | 各国统计局数据         |     |\n| 食品安全 | 成人年摄入量（C1）  | C1=D×C×365（D为日均消费量）                                     | FAO食品消费指数       |     |\n|      | 儿童年摄入量（C2）  | C2=0.5×C1（儿童消费量为成人50%）                                  | FAO食品消费指数       |     |\n|      | 超标风险率（C3）   | C3=1（若 C1>100 Bq／年），否则0                                 | IAEA2024指南第7.3章 |     |\n|      | 食品信任度下降（C4） | C4=0.03C（C 单位：Bq/L）                                     | 全球消费者信心调查       |     |\n|      | 食品替代成本（C5）  | C5=0.01C（C 单位：Bq/L）                                     | 各国食品价格数据库       |     |\n  \n---  \n  \n#### 2. 评估指标量化  \n  \n用上图计算方法，计算出每个国家相应原始指标，填到下表←  \n 原始值表\n \n| 国家   | A1  | A2  | B1  | B2  | B3  | C1  | C2  | C3  | C4  | C5  |\n| ---- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 日本   |     |     |     |     |     |     |     |     |     |     |\n| 韩国   |     |     |     |     |     |     |     |     |     |     |\n| 美国   |     |     |     |     |     |     |     |     |     |     |\n| 加拿大  |     |     |     |     |     |     |     |     |     |     |\n| 中国   |     |     |     |     |     |     |     |     |     |     |\n| 澳大利亚 |     |     |     |     |     |     |     |     |     |     |\n\n---  \n  \n#### 3. 指标标准化  \n  \n上面原始值表计算完填完表格后，把每列最大和最小值分别找出来，对应填到下面这幅 min-max 表格←  \n  \n| 指标      | A1  | A2  | B1  | B2  | B3  | C1  | C2  | C3  | C4  | C5  |     |\n| ------- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| min(Xj) |     |     |     |     |     |     |     |     |     |     |     |\n| max(Xj) |     |     |     |     |     |     |     |     |     |     |     |\n  \n**标准化公式（min-max法）：**  \n$$X_{ij} = \\frac{X_{ij} - \\min(X_j)}{\\max(X_j) - \\min(X_j)}  $$\n其中min(Xj),max(Xj)为第j项指标的6过最小值,最大值.\n用标准化公式计算出标准化值填到下面那个表格，下面表格里的数据是示范，数据不正确的，只是表格格式这样，把数据替换成我们自己计算的就好了\n\n---  \n  \n#### (3) 6国完整标准化值表  \n  \n| 国家   | A1'   | A2'   | B1'   | B2'   | B3'   | C1'   | C2'   | C3'   | C4'   | C5'   |     |\n| ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | --- |\n| 日本   | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |     |\n| 韩国   | 0.818 | 0.995 | 0.833 | 0.833 | 0.833 | 0.738 | 0.738 | 1.000 | 0.833 | 0.833 |     |\n| 美国   | 0.260 | 0.913 | 0.255 | 0.255 | 0.255 | 0.153 | 0.153 | 1.000 | 0.255 | 0.255 |     |\n| 加拿大  | 0.213 | 0.877 | 0.204 | 0.204 | 0.204 | 0.097 | 0.097 | 0.000 | 0.204 | 0.204 |     |\n| 中国   | 0.039 | 0.438 | 0.037 | 0.037 | 0.037 | 0.001 | 0.001 | 0.000 | 0.037 | 0.037 |     |\n| 澳大利亚 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 |     |\n  \n---  \n  \n#### 4. 权重的确定  \n  \n采用熵权法-AHP组合算法来确定\n  \n##### （1）熵权法（客观权重 WO）  \n  \n1. 计算指标概率：$$P_{ij} = \\frac{X_{ij}'}{\\sum_{i=1}^6 X_{ij}'}  $$\n  \n2. 计算信息熵：$$E_j = -\\frac{1}{\\ln 6} \\sum_{i=1}^6 P_{ij} \\ln P_{ij}   (\\ln{6}\\approx1.792 ) $$\n  \n3. 计算客观权重：$$W_{o,j} = \\frac{1 - E_j}{\\sum_{j=1}^{10}(1 - E_j)} $$\n  \n---  \n  \n##### （2）AHP 法（主观权重 Ws）  \n\n### （2）AHP法\n\n1. 层次结构：  \n目标层（核废水对国家影响评估）→准则层（3个：海洋生态A、渔业经济B、食品安全C）→指标层（10个：A1核素累积量、A2浮游生物死亡率、B1渔获量下降率、B2出口损失、B3收入减少、C1成人摄入量、C2儿童摄入量、C3超标风险、C4信任度、C5替代成本）；\n\n#### 一级指标权重：\n\n1. 准则层判断矩阵（两两比较标度）\n\n| 准则层        | 海洋生态(A) | 渔业经济(B) | 食品安全(C) |\n|---------------|-------------|-------------|-------------|\n| 海洋生态(A)   | 1           | 3           | 1/2         |\n| 渔业经济(B)   | 1/3         | 1           | 1/5         |\n| 食品安全(C)   | 2           | 5           | 1           |\n\n#### 二级指标权重：\n\n（A1、A2指标）\n\n| 海洋生态二级指标 | A1（核素累积量） | A2（浮游生物死亡率） |\n|------------------|------------------|----------------------|\n| A1               | 1                | 3                    |\n| A2               | 1/3              | 1                    |\n（B1、B2、B3） \n\n| 渔业经济二级指标 | B1（渔获量下降率） | B2（出口损失） | B3（收入减少） |\n| -------- | ---------- | -------- | -------- |\n| B1       | 1          | 5        | 4        |\n| B2       | 1/5        | 1        | 1/2      |\n| B3       | 1/4        | 2        | 1        |\n\n（C1、C2、C3、C4、C5）  \n\n| 食品安全二级指标 | C1（成人摄入量） | C2（儿童摄入量） | C3（超标风险） | C4（信任度） | C5（替代成本） |\n| -------- | --------- | --------- | -------- | ------- | -------- |\n| C1       | 1         | 3         | 5        | 7       | 7        |\n| C2       | 1/3       | 1         | 1/2      | 3       | 5        |\n| C3       | 1/5       | 2         | 1        | 4       | 6        |\n| C4       | 1/7       | 1/3       | 1/4      | 1       | 3        |\n| C5       | 1/7       | 1/5       | 1/6      | 1/3     | 1        |\n\n下面这个图就是计算好的AHP的Ws权重，直接套用，你把全局权重那一列扣出来，直接放进下面组合权重Ws那栏就行。\n\n| 指标 | 准则层权重 | 局部权重 | 全局权重（AHP主观权重 Ws） | 备注 |\n|------|------------|----------|----------------------------|------|\n| A1   | 0.309      | 0.750    | 0.232                      | 海洋生态-核素累积量 |\n| A2   | 0.309      | 0.250    | 0.077                      | 海洋生态-浮游生物死亡率 |\n| B1   | 0.110      | 0.681    | 0.075                      | 渔业经济-渔获量下降率 |\n| B2   | 0.110      | 0.118    | 0.013                      | 渔业经济-出口损失 |\n| B3   | 0.110      | 0.201    | 0.022                      | 渔业经济-收入减少 |\n| C1   | 0.581      | 0.425    | 0.247                      | 食品安全-成人摄入量 |\n| C2   | 0.581      | 0.177    | 0.103                      | 食品安全-儿童摄入量 |\n| C3   | 0.581      | 0.273    | 0.159                      | 食品安全-超标风险 |\n| C4   | 0.581      | 0.084    | 0.049                      | 食品安全-信任度 |\n| C5   | 0.581      | 0.042    | 0.024                      | 食品安全-替代成本 |\n| 合计 | 1.000      | —        | 1.000                      | 权重归一化验证 |\n\n---  \n  \n##### （3）组合权重（Wj = 0.6×Wo + 0.4×Ws）  \n  \n| 指标 | Wo   | Ws   | Wj   |  \n|------|--------|--------|--------|  \n| A1   | 0.115 | 0.124 | 0.118 |  \n| A2   | 0.093 | 0.085 | 0.090 |  \n| B1   | 0.110 | 0.105 | 0.108 |  \n| B2   | 0.095 | 0.092 | 0.094 |  \n| B3   | 0.084 | 0.078 | 0.082 |  \n| C1   | 0.159 | 0.163 | 0.161 |  \n| C2   | 0.103 | 0.100 | 0.102 |  \n| C3   | 0.069 | 0.067 | 0.068 |  \n| C4   | 0.086 | 0.089 | 0.087 |  \n| C5   | 0.036 | 0.037 | 0.036 |  \n  \n---  \n  \n#### 5. 综合评分与 K-means 聚类分类  \n  \n**综合风险评分**\n\n**用下面综合风险得分计算公式求出****6****个国家分别评分\n综合风险得分计算：  \n  $$S_i = \\sum_{j=1}^{10} W_j \\cdot X_{ij} $$ \n  \n计算出6个国家综合风险评分  \n确认聚类数 K  \n\n下面公式里的 x 其实就是上面一步计算出来的 Si。\n\n#### (1) 计算不同 K 值的 WCSS（簇内平方和）\n\n| K值 | 聚类方案           | WCSS 计算过程                                                                 | WCSS 结果 |\n|-----|--------------------|------------------------------------------------------------------------------|-----------|\n| 1   | 所有国家为1个簇    | (0.991−μ)² + (0.857−μ)² + … + (0.000−μ)²，μ=0.433                            | 0.926     |\n| 2   | 高风险（日、韩）+其余 | 高风险簇：(0.991−0.924)² + (0.857−0.924)² ≈ 0.009<br>其余簇：(0.402−0.188)² + … + (0.000−0.188)² ≈ 0.1074 | 0.1164    |\n| 3   | 高、中、低三簇      | 高风险：(0.991−0.924)² + (0.857−0.924)² ≈ 0.009<br>中风险：(0.402−0.3455)² + (0.289−0.3455)² ≈ 0.0063<br>低风险：(0.061−0.0305)² + (0.000−0.0305)² ≈ 0.0018 | 0.0171    |\n**（2）****肘部法则判断**\n\n**用上面一部WCSS****结果，你电脑算上面一部就行，这个我拿结果写**  \n  \n---  \n  \n##### 2. K-means 迭代计算过程（K=3）  \n  \n###### （1）初始聚类中心选择：  \n  \n- μ1 = 0.991（日本）  \n- μ2 = 0.402（美国）  \n- μ3 = 0.000（澳大利亚）  \n  \n###### （2）第一次迭代：分配样本到最近簇（欧氏距离$d=|x-\\mu_k|$）  \n  \n| 国家   | 到μ1距离 | 到μ2距离 | 到μ3距离 | 分配簇 |     |\n| ---- | ----- | ----- | ----- | --- | --- |\n| 日本   | 0     | 0.589 | 0.991 | 簇1  |     |\n| 韩国   | 0.134 | 0.455 | 0.857 | 簇1  |     |\n| 美国   | 0.589 | 0     | 0.402 | 簇2  |     |\n| 加拿大  | 0.702 | 0.113 | 0.289 | 簇2  |     |\n| 中国   | 0.930 | 0.341 | 0.061 | 簇3  |     |\n| 澳大利亚 | 0.991 | 0.402 | 0     | 簇3  |     |\n  上面里面表格里的数据不对，要重新自己计算，公式就是欧式距离，初始中心用的数值就是前面综合风险算的评分\n###### （3）第一次迭代:更新聚类中心：  \n  \n- 簇1（日、韩）：μ = 0.924    \n- 簇2（美、加）：μ = 0.3455    \n- 簇3（中、澳）：μ = 0.0305    \n  \n###### （4）第二次迭代：重新分配样本（距离新中心）  \n  \n| 国家       | 到μ1距离 | 到μ2距离 | 到μ3距离 | 分配簇 |  \n|------------|------------|------------|------------|--------|  \n| 日本       | 0.067      | 0.6455     | 0.9605     | 簇1    |  \n| 韩国       | 0.067      | 0.5115     | 0.8265     | 簇1    |  \n| 美国       | 0.5785     | 0.0565     | 0.3715     | 簇2    |  \n| 加拿大     | 0.635      | 0.0565     | 0.2585     | 簇2    |  \n| 中国       | 0.863      | 0.315      | 0.0305     | 簇3    |  \n| 澳大利亚   | 0.924      | 0.3455     | 0.0305     | 簇3    |  \n  计算步骤跟这里面一样，数据都要改\n\n\n#### (5) 收敛判断  \n第二次迭代后，聚类中心为  \n- μ₁ = 0.924  \n- μ₂ = 0.3455  \n- μ₃ = 0.0305  \n\n与第一次迭代更新后的中心完全一致，迭代终止。\n\n---\n\n### 三、聚类结果与风险等级划分\n\n#### 1. 最终聚类中心与簇成员\n\n| 风险等级 | 聚类中心 μ | 包含国家       | 簇内样本综合得分范围 |\n|----------|-------------|----------------|----------------------|\n| 高风险   | 0.924       | 日本、韩国     | [0.857, 0.991]       |\n| 中风险   | 0.3455      | 美国、加拿大   | [0.289, 0.402]       |\n| 低风险   | 0.0305      | 中国、澳大利亚 | [0.000, 0.061]       |",
  "科研-动作分类\\BDC-CLIP.md": "##### 标题\n**《BDC-CLIP: Brownian Distance Covariance for Adapting CLIP to Action Recognition》**\n（BDC-CLIP：应用布朗距离协方差来适应CLIP于动作识别）\n\n---\n\n| **类别**    | **关键词**                                                |\n| --------- | ------------------------------------------------------ |\n| **任务核心**  | 动作识别 (Action Recognition)                              |\n| **创新任务**  | **零样本/少样本动作识别**（Zero-shot/Few-shot Action Recognition） |\n| **输入类型**  | **视频（RGB 帧序列）** + **动作文本描述**                           |\n| **核心挑战**  | **细粒度语义对齐**、**忽略局部时空线索**、**非线性依赖建模**                   |\n| **主要框架**  | **BDC-CLIP 框架**                                        |\n| **关键技术**  | **BDC（布朗距离协方差）**、CLIP、多模态对齐                            |\n| **评估/设置** | **Zero-Shot**、**Few-shot**、Base-to-Novel、线性/非线性关系      |\n\n**老方法 vs. 新方法：**\n\n- **以前的方法 (老方法)：** 大多使用**余弦相似度**（等同于皮尔逊相关系数）来比较视频和文本的**全局特征**。这种方法只能捕捉**线性**关系，并且会**忽略**视频和文本中编码**关键时空线索的局部 Tokens**。\n    \n- **新方法 (这篇文章)：** 引入 **BDC（布朗距离协方差）作为新的相似性度量。BDC 能够建模所有局部视觉 Tokens**与**所有局部文本 Tokens**之间的**复杂依赖关系（包括线性和非线性）**。\n    \n\n**模型拆解（解决细粒度对齐问题）：**\n\n1. **特征提取（CLIP 编码器）：** 负责将视频序列和动作文本分别编码，生成各自的**局部特征 Tokens**。\n    \n2. **对齐核心（BDC）：** 负责替换传统的相似度计算，计算视频和文本**所有局部 Tokens**之间的**精细化关联度**。\n\n**它是怎么做到的？**\n\n1. **更复杂的对齐：** BDC 不仅看视频和文字的**整体印象**，它还能捕捉到它们之间**所有复杂、细微的对应关系**（比如文字“挥拍”和视频里手部的高速运动）。\n    \n2. **细粒度捕捉：** 这使得模型能够关注到那些**关键的、细小的时空线索**，从而更好地理解“打网球”和“打高尔夫”这种动作细节相似但类别不同的动作。\n\n布朗距离协方差数据,实验设置,指标.\n自己写,不用AI写what,input,output,data,metric,motivation,how,methology in detail,**how**,具体公式.\n![[Pasted image 20251107185030.png]]\n会议的所有文章全部搜集\n每个都 what why how\n\n开源代码下下来跑\n结果能否复现\n\n---\n### 输入和输出\n\n##### 数据流动\n- `特征提取`->`模态对齐`\nRGB视频帧序列和文本描述（或类别名）  \n--> **CLIP 编码器**生成各自的**局部特征 Tokens**（视频 Tokens 编码时空，文本 Tokens 编码单词语义）\n--> **BDC** (布朗距离协方差) 替代传统的余弦相似度(根据余弦值得到相似度分数)，而是计算**所有局部 Tokens**之间的**复杂依赖关系(包括线性和非线性)** ,生成精细的**对齐分数(BDC距离,越大视觉和语义越对齐)** \n--> BDC输出的对齐分数作为**损失函数的一部分**,输出动作类别标签(分数最高的几个)\n\n##### 详细数据流动\n\n|**核心要素**|**具体内容 (通俗解释)**|\n|---|---|\n|**输入 (Input)**|**RGB 视频帧序列**（用于提取视觉特征）**+ 动作文本描述**（用于提取语义特征）|\n|**输出 (Output)**|**预测的动作类别标签**|\n\n| **阶段**                           | **核心技术/模型**                       | **步骤与功能**                                                               |\n| -------------------------------- | --------------------------------- | ----------------------------------------------------------------------- |\n| **阶段 1：特征提取 (Feature Encoding)** | **CLIP 的视觉/文本编码器**                | **功能：从不同模态中提取局部特征 Tokens**                                              |\n|                                  | **输入：** RGB 视频帧序列 / 动作文本          |                                                                         |\n| **步骤 1：视频特征提取**                  | **视觉编码器**                         | 将视频序列分解并编码，生成**大量的局部视觉 Tokens**，这些 Tokens 编码了细微的**时空线索**。               |\n| **步骤 2：文本特征提取**                  | **文本编码器**                         | 将动作文本编码，生成**局部的文本 Tokens**（每个单词或子词的特征）。                                 |\n| **阶段 2：模态对齐 (BDC Alignment)**    | **BDC（布朗距离协方差）**                  | **功能：捕捉线性和非线性关系并对齐**                                                    |\n|                                  | **输入：** 局部视觉 Tokens / 局部文本 Tokens |                                                                         |\n| **步骤 3：计算局部 Tokens 关系**          | **BDC 核心计算**                      | **BDC** 计算**所有视觉局部 Tokens**和**所有文本局部 Tokens**之间的**复杂统计依赖关系**（包括线性和非线性）。 |\n| **步骤 4：生成对齐分数**                  | **BDC 距离**                        | BDC 计算结果生成一个**细粒度的对齐分数**，替代传统的全局余弦相似度。                                  |\n| **最终输出**                         | **动作识别分类**                        | **功能：动作分类**                                                             |\n|                                  | **输入：** BDC 对齐分数                  |                                                                         |\n| **步骤 5：最终识别**                    | **分类**                            | 根据输入视频特征与所有候选动作文本特征的 **BDC 分数**，确定关联性最强（BDC 分数最高）的动作类别作为最终输出。           |\n\n---\n\n### 📄 文章分析：《BDC-CLIP》\n\n| **框架要素**                       | **核心认知与分析 (通俗易懂的解释)**                                                                                                                                                                                                                                                                                                 | **核心概念与引用**                                                                                                                           |\n| ------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |\n| **1. 动作分类核心**                  | **核心问题：** 如何让像 CLIP 这样的大型**视觉-语言模型**，更有效地处理**动态的视频动作分类**任务。人类动作识别不仅需要看画面（空间），还需要看动作随时间的变化（时间），以及动作的文字描述（语言）。                                                                                                                                                                                                          | 任务：**Video Action Recognition** (视频动作识别) / **Action Classification** (动作分类)。 核心挑战：**Fine-grained Spatio-temporal Cues**（细粒度的时空线索）的捕捉。 |\n| **2. 主干知识**                    | **现有问题：** 现有的方法（如 ViFi-CLIP）通常只计算视频的**全局特征**和文本的**全局特征**之间的相似度（使用**余弦相似度**）。这就像只比较“视频的整体印象”和“动作名字的整体印象”，会忽略掉视频中细微的动作细节和文字中精确的描述。 **解决办法：** 引入了**BDC (Brownian Distance Covariance，布朗距离协方差)**。它是一种统计工具，可以捕捉两个复杂数据集合之间**所有**（线性和非线性）的复杂依赖关系。                                                                            | **核心技术：** **BDC** (布朗距离协方差)。 **作用：** 建模所有**局部（Token）的视觉特征与文本特征之间的复杂关系，而不仅仅是全局特征。                                                      |\n| 3. 未涵盖知识                       | 尽管 BDC-CLIP 在利用视觉-语言知识进行泛化方面表现出色，但它可能没有涵盖**以下方面： **1. 动作生成：** 如何根据文本生成动作序列（如第一篇文章）。 **2. 3D骨架驱动：** 专注于 RGB 视频的特征，而没有利用人体**骨架关节**等精确的 3D 运动数据。 **3. 模型效率/部署：** 模型的计算复杂度（尤其是在引入 BDC 后）以及在实际低资源设备上的运行效率可能不是重点。                                                                                                           | -                                                                                                                                     |\n| **4. 几篇文章目的区别**                | **本篇目的：** 专注于**改进现有大型视觉-语言模型（CLIP）在视频动作分类上的对齐和泛化能力**，通过更高级的统计方法（BDC）来**精确捕捉细粒度的时空和语言关系**。                                                                                                                                                                                                                             | **侧重：** **模型对齐（Alignment）和细粒度特征建模**。                                                                                                  |\n| **5. 三篇文章的`few-shot`分别是什么**    | **BDC-CLIP 的 Few-shot：** 模型利用 BDC-CLIP 在海量数据上学到的**高泛化性语义对齐空间**。在这个空间中，**新动作类别**的少量样本（K-shot）的特征会非常紧密地聚集在一起。 **实现方式：** 学习一个**更鲁棒的语义嵌入空间**，使得在只有极少量样本时，模型也能准确地找到它们的原型中心，并进行准确分类。                                                                                                                                        | **应用场景：** BDC-CLIP 在 Zero-shot、Few-shot、Base-to-Novel (基类到新类) 和 Fully Supervised (全监督) **四种设置**下都取得了最优结果，体现了其在**泛化学习**上的全面优势。         |\n| **6. Why-What-How (动机-内容-方法)** | * **Why (动机):** 现有的 CLIP 适应方法只用**余弦相似度**（一种简单的线性相关性度量）来对齐全局特征，这无法捕捉到视频和文本中复杂的**非线性依赖**和**局部细节**（比如手部动作和文字“举起”的对应关系）。 * **What (内容):** 提出了 **BDC-CLIP 框架**，利用 **BDC** 代替传统的余弦相似度进行视频-语言的特征对齐。 * **How (方法):** **BDC 模块**：通过计算视觉特征和文本特征之间所有 Token 对的**布朗距离协方差**，来衡量它们的依赖性，并将其用作损失函数的一部分来优化模型。这使得模型可以**同时关注**全局和局部的时空细节。 | **关键创新：** 用 **BDC** 代替 **Cosine Similarity**（余弦相似度）作为度量标准，实现更深层的多模态关联。                                                                |\n| **7. 大模型和方法**                  | **列举的大模型/方法：** 骨干模型是**CLIP**（大规模视觉-语言预训练模型）。以及其视频领域的变体，如 **ViFi-CLIP**。 **现有大模型做法：** 这篇文章是**“站在巨人的肩膀上”**。它接受 CLIP 带来的巨大好处（强大的泛化能力和语义理解），但指出其局限性（对动态视频细节的对齐不足），并通过引入 BDC 这种数学工具来**“修复”**或**“增强”**大模型的对齐机制。                                                                                                             | BDC-CLIP 框架的核心就是对**CLIP 架构**的**适应性增强**。                                                                                               |\n",
  "科研-动作分类\\raw_files\\BDC_CLIP_Brownian_Distance.pdf": "Binary File CANNOT Be Read",
  "科研-动作分类\\raw_files\\YouThinkYouACT.pdf": "Binary File CANNOT Be Read",
  "科研-动作分类\\You Think, You ACT.md": "##### 标题\n**《You Think, You ACT: The New Task of Arbitrary Text to Motion Generation》**\n（你思考，你行动：任意文本到动作生成的新任务）\n\n---\n\n\n| **类别**    | **关键词**                                      |\n| --------- | -------------------------------------------- |\n| **任务核心**  | 动作生成 (Motion Generation)                     |\n| **创新任务**  | 任意文本到动作 (Arbitrary Text to Motion, A2M)      |\n| **输入类型**  | **情景文本** (Scene Texts)                       |\n| **核心挑战**  | **多解范式** (Multi-solution Paradigm)           |\n| **主要框架**  | **TAAT 框架** (Think and Act)                  |\n| **关键技术**  | **LLM (大语言模型)**、**Transformer**、VQ-VAE、解耦式架构 |\n| **评估/设置** | **Zero-Shot**、Hit Accuracy (HA)、HUMANML3D++  |\n**老方法 vs. 新方法：**\n\n- **以前的方法 (老方法)：** 只能接收**明确的动作指令**，比如你输入“请跑步”，它就生成跑步的动作。\n    \n- **新方法 (这篇文章)：** 可以接收**复杂的情景描述**，比如你输入“她走在路上，但迷路了”。电脑需要自己**推理**（*“迷路了”意味着什么？*），然后生成一个**反应性的动作**（比如停下来、张望或挠头）。\n\n**模型被拆成了两部分，就像有了“大脑”和“身体”：**\n\n1. **“大脑” (LLM 大模型)：** 负责阅读复杂的情景描述，然后**推理**出几种合理的**动作指令**（比如：停下 → 张望 → 叹气）。\n    \n2. **“身体” (Transformer 模型)：** 负责接收这些指令，然后将它们平滑、连贯地**转化为实际的骨架动作**序列。\n\n##### 提出了新的评估指标\n由于一个情景文本可以对应**多种**合理的动作（即“多解范式”），传统的评估指标无法准确衡量模型的表现。因此，文章提出了新的评估指标来解决这个问题：\n\n- **多解命中准确率 (Hit Accuracy, HA)：** 衡量模型生成的动作是否与**专家标注的多个合理动作**中的**任一动作**相似。这解决了“情景多解”的问题。\n    \n- **多解平均距离 (Multi-solution Hausdorff Distance, MHD)：** 衡量模型生成的动作与所有合理动作之间的平均距离，以评估生成的动作**与所有可能解的距离**。\n\n---\n### 输入和输出\n\n##### 数据流动\n - `Think`->`Act`\n任意情景文本(可能不包含具体动作) \n--> LLM根据文本生成具体动作指令 \n--> Transformer预测并生成一长串**离散动作代码序列**(数字序列)(Transformer的预测是基于VQ-VAE,VQ-VAE首先要被喂海量动作数据,并将相似的连续的动作片段归类,形成一个\"词汇表\") \n--> VQ-VAE解码器根据自己的词汇表,将Transformer输出的离散动作序列解码为连续的3D骨架动作序列.\n\n##### 详细数据流动\n\n| **核心要素**        | **具体内容 (通俗解释)**                                                   |\n| --------------- | ----------------------------------------------------------------- |\n| **输入 (Input)**  | **任意情景文本（Arbitrary Scene Text）**                                  |\n| **输出 (Output)** | **3D 人体骨架动作序列（3D Human Skeleton Motion Sequence）(即一系列连续的人体关节坐标)** |\n\n| **阶段**              | **核心技术/模型**                                                                          | **步骤与功能**        |\n| ------------------- | ------------------------------------------------------------------------------------ | ---------------- |\n| **阶段 1：思考 (Think)** | **LLM（大型语言模型，充当“大脑”）**                                                               | **功能：认知推理与多解生成** |\n|                     | **输入：** 情景文本（如：“她迷路了”）                                                               |                  |\n| **步骤 1：情景理解**       | LLM 接收文本，理解其中的**情绪、意图和上下文**。                                                         |                  |\n| **步骤 2：动作指令生成**     | LLM 根据理解，**推理**并生成**多组**合理的、明确的**动作指令**（例如，输出可能是：`[指令1: 停止并查看地图]`、`[指令2: 缓慢行走并张望]`）。 |                  |\n| **阶段 2：行动 (Act)**   | **Transformer 模型（充当“身体”）**                                                           | **功能：动作序列生成与平滑** |\n|                     | **输入：** LLM 生成的**动作指令**                                                              |                  |\n| **步骤 3：离散编码解码**     | 模型首先将动作数据（关节坐标）通过 **VQ-VAE** 转化为离散的“动作代码”（像文字一样），以便 Transformer 处理。                  |                  |\n| **步骤 4：序列生成**       | Transformer 接收动作指令，并**一步步**（一个时间步一个时间步）生成对应的动作序列代码。                                  |                  |\n| **步骤 5：连贯性保证**      | <u>在生成每一步时，模型会参考**前一个动作的结尾姿态**，确保动作序列是**平滑、连贯**的，避免出现“鬼畜”或不自然的跳跃。</u>                |                  |\n| **最终输出**            | **连贯的 3D 骨架动作序列。**                                                                   |                  |\n计算这个距离\nllm\n每部分语言怎样的作用,组成\n实验设置,跑了怎么样的实验,如何的数据,指标\n\nyayt 推理?动作视频?兴趣点\n\n\n\n---\n\n### 📄 文章分析：《You Think, You ACT》\n\n| **框架要素**                       | **通俗解读 (针对动作分类核心的衍生任务)**                                                                                                                                                                                       | **核心概念与引用**                                                                                                                              |                                                                                                        |\n| ------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |\n| **1. 动作分类核心**                  | 这篇文章没有做传统的“动作分类”，而是将任务核心从**“动作生成”**推向了更复杂的**“情景反应生成”**。它要解决的核心问题是：如何根据一句描述**情景或事件**的文本（而不是直接的动作指令），生成一个**合理且有反应**的动作。                                                                                          | 任务：Arbitrary Text to Motion Generation（任意文本到动作生成）1111。<br><br>核心挑战：Multi-solution Paradigm（多解范式），即一个情景文本可以对应多种合理的动作，这是传统 T2M 无法处理的 2222。 |                                                                                                        |\n| 2. 主干知识                        | * Transformer: **用来生成动作序列**。它负责将思考模型给出的指令，一步步转化为具体的肢体动作。3<br><br>* VQ-VAE (离散编码): 将复杂的连续动作数据转化为离散的“动作词汇表”（Codebook），从而让 Transformer 这种基于序列的模型能更好地处理。 4<br><br>* LLM (大语言模型): 负责理解复杂的情景文本，充当人类的“大脑”进行认知推理。 5555 | 模型基础是：VQ-VAE + Transformer + LLM。                                                                                                        |                                                                                                        |\n| 3. 未涵盖知识                       | 这篇文章关注的是“生成”任务，因此没有深入探讨以下内容： * 传统动作分类算法： 如如何识别和标记一个已知视频中的动作（例如 3D CNN, TSM 等）。 * 多模态融合（视频+文本）： 文章只用文本生成动作，没有涉及从视频中学习上下文信息的方法。                                                                                  | -                                                                                                                                        |                                                                                                        |\n| 4. 几篇文章目的区别                    | 本篇目的： 打破现有“文本到动作”任务中文本输入受限的僵局，扩展到可接受任意情景描述**，并解决由此带来的多解和评估问题** 6666。<br><br>(注：此部分完整回答需等待其他两篇文章)                                                                                                               | -                                                                                                                                        |                                                                                                        |\n| **5. `few-shot`设置**            | 本文主要侧重于验证模型的Zero-Shot能力，而非Few-shot。<br><br>Zero-Shot 设置： 模型仅使用传统的动作文本（Action Text）数据集进行训练，然后直接用全新的情景文本 (Scene Text) 进行测试，以验证模型对未见过场景的泛化理解能力 7。                                                                 |                                                                                                                                          | **Zero-shot 表现：** 在 Zero-shot 设置中，本文提出的 TAAT 模型在 Hit Accuracy 等指标上优于所有现有模型 8。                          |\n| **6. Why-What-How (动机-内容-方法)** | * Why (动机): 现有的 T2M 只能响应如“走路”的明确指令，无法在开放世界游戏或虚拟人交互中处理“有人向你打了一拳”这类需要推理和反应的场景描述 9。<br><br>* What (内容): 提出了 TAAT 框架、HUMANML3D++ 数据集和多解评估指标（HA/MHD）10。<br><br>* How (方法): 采用**“思考-行动”**的分步策略。                      | 核心框架： TAAT (Think and Act) 11。<br><br>核心数据： HUMANML3D++ (新增了 135k 情景文本) 12。                                                              |                                                                                                        |\n| 7. 大模型                         | 文章将大模型（LLM）作为框架中的**“大脑”**，专门用于理解复杂的**情景语义**，并将其转换为一系列明确的**动作指令**。                                                                                                                                              |                                                                                                                                          | 使用的大模型： LLaMA (通过 LoRA 进行微调) 13131313。<br><br>作用： 场景理解、认知处理、提取多组合理的动作指令（Action Instructions） 14141414。 |\n| **8. 方法 (Methodology)**        | TAAT 框架：<br><br>1. Think (思考) 阶段： LLM 接收情景文本 (Scene Text)，输出多组可能的动作指令集 (Action Instructions) 15。<br><br>2. Act (行动) 阶段： Transformer 接收指令，并利用前一个动作的结尾姿态信息（last n indices）来指导下一个动作的生成，从而保证动作序列连贯平滑 16161616。     |                                                                                                                                          | **解耦式架构：** 将“文本理解”和“动作执行”分离，以有效处理多解任务 17。                                                              |\n",
  "科研-动作分类\\两篇文章的总结和对照.md": "### 1. You Think, You ACT(TAAT):\n[[You Think, You ACT]]\n![[You Think, You ACT#数据流动]]\n\n---\n### 2. BDC-CLIP\n[[BDC-CLIP]]\n![[BDC-CLIP#数据流动]]\n\n---\n### 综合总结：两篇文章目的对比\n\n| **文章**                    | **核心任务** | **数据模态**    | **解决的核心痛点**                                | **目标方向**         |\n| ------------------------- | -------- | ----------- | ------------------------------------------ | ---------------- |\n| **1. You Think, You ACT** | **动作生成** | 文本 → 3D 骨架  | **认知推理**：解决复杂情景下动作的**多解性**和**合理性**。        | 虚拟人、游戏、人机交互      |\n| **2. BDC-CLIP**           | **动作分类** | 文本 + RGB 视频 | **多模态对齐**：解决 **CLIP** 适应视频时的**细粒度语义对齐**不足。 | 零样本/少样本泛化、多模态理解  |\n\n---\n##### 附录:科研文章阅读需求\n[[科研文章阅读需求]]\n",
  "科研-动作分类\\科研文章阅读需求.md": "### 科研文章阅读主要要求\n\n**两篇文章只是都是与动作分类相关**,以下是阅读需求:\n* 动作分类\n* 主干知识\n* 没有涵盖的知识\n* 几篇文章目的的区别\n* 三篇文章的`few-shot`分别是什么\n* 在这几篇文章之中,出于什么目的,提出了什么问题,引入了怎样的方法来完成什么结果.(即\"why what how\")\n* 列举了哪些大模型和哪些方法,现有的大模型是如何做的\n\n### 2篇文章的地址\n\n1. [文章1](https://arxiv.org/pdf/2404.14745)\n2. [文章2](https://openreview.net/pdf?id=fjXcRSfyIV)\n\n",
  "计算机组成原理\\static\\B通路.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\I型指令数据通路.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\I通路.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\Junk.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\Nop.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\R型指令数据通路.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\R通路.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\S型指令数据通路.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\不能使用旁路的情形.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\原码反码补码.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\取指令数据通路.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\各类型指令二进制字段.jpg": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\多周期流水线图.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\旁路.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\时空图.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\流水线.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\调整代码.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\static\\进制转换.png": "Binary File CANNOT Be Read",
  "计算机组成原理\\计算机组成原理.md": "# CPU性能指标\n### CPU 基本性能参数\n**CPU主频** (时钟频率)=1/CPU时钟周期\n**CPI**: 执行一条指令所需的时钟周期数.\n1. 不同指令的PCI不同,相同指令的CPI也不一定相同.\n2. 整体CPI:各类指令的CPI的加权平均和,即: $整体CPI = \\sum \\left( 各类指令比例 \\times 该类指令CPI \\right)$\n3. $执行一条指令的耗时=CPI \\times CPU时钟周期$.\n4. 整个程序的耗时(CPU执行时间)=CPU时钟周期数/时钟频率\n**SPEC分值**=参考时间/实际时间\n**IPS**: 每秒执行指令的条数=时钟频率/平均CPI\n**FLOPS**: 每秒执行浮点运算的次数,与时钟频率正相关.\n\tIPS和FLOPS前面可加上计量单位,如MIPS,MFLOPS,GIPS,TIPS\n\n### 并行计算\n**加速比**: $$ S(p)=\\frac{T(1)}{T(p)} $$\n\t其中T(i)为i个处理器并行计算的处理时间.\n**Amdahl定律**:$$ S(p)=\\frac{1}{(1-f)+\\frac{f}{p}} $$\n\t其中f为可并行部分的比例,p为并行的处理器数量.\n\n---\n# RISC-V汇编语言\n### 基本指令\n`add c,a,b`   # c=a+b;\n`sub c,a,b`    # c=a-b;\n`addi c,a,10`   # c=a+10,立即数操作\n`lui rd,imm`   # rd=imm<<12\n`x0`   # x0硬连线到0,就是一个可以用于add的0,无论是地址还是算数运算,不代表寄存器.\n\t注:add和addi也可以用于地址运算,地址运算和数值运算的判别如下:\n\t1.  数值运算:普通的加减法,如add x9,x8,x7  addi x9,x8,10\n\t2.  地址运算:结合上下文,如:\n```asm\nli x11,16      # x11=offset(4)*4\nadd x12,x10,x11    # x12是x10偏移4位的地址 \n#之后就会用lw或sw指令来访问这个地址\nlw x13,0(x12)   #x13是x12对应的数值\n```\n\n### 跳转指令\n> `jal(jump and link),jalr(jump and link register)`\n\n`ra` : 即x1\n`jal rd,offset` 无条件跳转指令\n1.  保存返回地址(rd=PC+4,将下一条指令的地址存入rd)\n2.  跳转(PC=PC+offset,更新PC,跳转到新地址PC+offset)\n\t常用的: `jal ra,Function` 调用Function\n`jalr rd,imm(rs1)` 寄存器简介跳转指令,用于实现函数返回和函数调用.\n1.  保存返回地址(rd=PC+4,将下一条指令的地址存入rd)\n2.  跳转(PC=rs1+imm,更新PC,跳转到新地址rs1+imm,并将最低有效位清零(&~1,保证跳转目标地址是2字节对齐的))\n\t常用的: `jalr x0,0(ra)` 即`ret`,回到函数调用的地方\n\n### 访存指令:\n>`lw(load word),sw(store word)`\n\n`lw reg,offset(base)`   # 将base指针偏移offset指向的数值加载(load)到寄存器reg\n`sw reg,offset(base)`   # 将寄存器reg的数值存储(store)到base指针偏移offset的位置\n\t其中offset为偏移量,即索引*4(跨越Byte的数量)\n\teg: 设A\\[0]的地址为x15,x10指向变量temp,则\n`lw x10,12(x15)`   # temp=A\\[3];\n`addi x10,x10,3 `  # temp+=3;\n`sw x10,36(x15)`    # A\\[9]=temp;\n\n### 条件判断和分支转移\n>`beq(equal),bne(not equal),blt(less than),bltu,ble(less equal),bge(greater equal).`\n\n`beq a,b,L`   # if(a\\==b)goto L;\n`bne a,b,L`   # if(a!=b)goto L;\n`blt a,b,L`   # < (以signed比较)\n`bltu a,b,L` # < (以unsigned比较)\n`ble a,b,L`   # <=  \n`bge a,b,L`   # >=\n\t注:只有<,<=,>=,=,没有> !!!\neg:\n```cpp\nif(i\\==j)f=g+h;\nelse f=g-h;\n```\n对应的汇编代码:\n```asm\nMain:\n   bne i,j,Else\n   add f,g,h\n   j Exit\nElse:\n   sub f,g,h\nExit:\n```\n\n### for循环\nC++片段:\n```cpp\nint A\\[20];//一个数组,有20个已经赋值的元素, A\\[0]地址在x8\nint sum=0;\nfor(int i=0;i<20;i++)sum+=A\\[i];\n```\n对应的汇编代码:\n```asm\nMain:\n   add x9,x8,x0   # 复制一份*p=&A[0]-->x9\n   li x10,0   # sum=0-->x10\n   li x11,0   # i=0-->x11\n   addi x13,x0,20   # 20-->x13\nLoop:\n   beq x11,x13,Done   # while(i!=20)\n   lw x12,0(x9)   # A[i]-->x12\n   add x10,x10,x12   # sum+=A[i];\n   addi x11,x11,1   # i++;\n   addi x9,x9,4   #*p++;\n   j Loop;   # 循环\nDone:\n```\n\n### 逻辑运算\n &:and   |:or   ^:xor   ~~!:not~~  \n`<<:sll(逻辑),sla(算数)\n`>>:srl(逻辑),sra(算数)\n\t还有如andi,slli之类的立即数操作.\n`srl rd,rs,n`  # 相当于$rd=\\frac{rs}{2^n}$,逻辑右移n位\n逻辑非的构造: `not rd,rs`  <=>  `xori rd,rs,-1`   # rd=NOT(rs)=rs XOR 0xFFFFFFFF  ($rs \\land {-1}$)\n\n### 伪指令\n`not a,b`   # `a=!b`  逻辑非\n`mv rd,rs`   # `addi rd,rs,0`  复制\n`li rd,13`   # `addi rd,x0,13`  立即数直接赋值\n`j L ` # `jal x0,L`  无条件跳转到L\n\n### 线程安全和原子性\n`lr.d t0,(a0)`  # 将内存地址a0的内容加载到t0\n`sc.d t2,t1,(a0)`  # 尝试将t1的内容存储到a0,存储成功时内存中的值更新,且t2返回0;失败则内存的值不变,t2返回非零值.\n\tlr.d和sc.d必须要在同一个循环中使用.\n\n### RISC-V指令类型\n##### R型 - 寄存器运算\n- 格式: `opcode | rd | funct3 | rs1 | rs2 | funct7`\n- 例: ADD, SUB, AND, OR\n##### I型 - 立即数运算/加载\n- 格式: `opcode | rd | funct3 | rs1 | imm[11:0]`\n- 例: ADDI, LW, JALR\n##### S型 - 存储\n- 格式: `opcode | imm[4:0] | funct3 | rs1 | rs2 | imm[11:5]`\n- 例: SW, SH, SB\n##### B型 - 分支\n- 格式: `opcode | imm[11|4:1] | funct3 | rs1 | rs2 | imm[12|10:5]`\n- 例: BEQ, BNE, BLT\n##### U型 - 高位立即数\n- 格式: `opcode | rd | imm[31:12]`\n- 例: LUI, AUIPC\n##### J型 - 跳转\n- 格式: `opcode | rd | imm[20|10:1|11|19:12]`\n- 例: JAL\n\n### 偏移量计算题 ? ? ?\n```markdown\n#偏移量计算题:\n目标地址=PC+偏移量\n对于偏移量:\n   1.jal:立即数为20位,拼接后左移一位=>有符号21位=>偏移量范围[−2^20,2^20−1]×2\n      =>目标地址范围=PC+偏移量范围=>最大地址和最小地址\n最小：**0x1FE00000**最大：**0x201FFFFE**\n   2.beq:立即数为12位,再左移一位=>有符号13位=>偏移量范围[-2^12,2^12-1]×2\n      =>目标地址范围=PC+偏移量范围=>最大地址和最小地址\n最小：**0x1FFFE000**最大：**0x20001FFE**\n```\n\n### 递归函数\n##### 栈的调用\n用sp寄存器保存栈的基地址,通常沿着高地址向低地址的方向扩展栈空间,\n\t通过递减sp值,不断push数据;\n\t通过递增sp值,不断pop数据.\n使用栈的步骤:\n\t`移动sp建立栈帧 -> 备份变量(sw) -> 主体操作 -> 重置变量(lw) -> 移回sp销毁栈帧`\n##### 递归函数的汇编\n使用栈汇编递归函数时,**必须要在栈帧中保存 ra** ,防止它们被下一层递归调用覆盖,\n即建立栈帧的时候参数必须要保存一个ra作为返回地址,\n然后就可以使用`jal ra,Function`调用其他函数.\n使用递归的步骤:\n\t`递归出口 -> 建立栈帧 -> 递归逻辑(调用递归函数) -> 销毁栈帧 `\n举例: cpp代码\n```cpp\nint test(int n) {\n    if (n == 0) return 0;\n    if (n == 1) return 1;\n    int r1 = test(n - 1);\n    int r2 = test(n - 2);\n    return 3 * r2 + 2 * r1;\n}\n```\n对应汇编代码:\n```asm\ntest:                       # int test(int x10)\n      #---------------------递归出口----------------------\n        beq     x10, x0, ret0       # if (x10 == 0)  return 0;\n        addi    x5,  x0, 1\n        beq     x10, x5, ret1       # if (x10 == 1)  return 1;\n      #---------------------建立栈帧-----------------------\n        addi    x2,  x2, -8         # sp -= 8\n        sw      x1,  4(x2)          # save ra\n        sw      x10, 0(x2)          # save 当前 n\n      #---------------------递归逻辑----------------------\n        addi    x10, x10, -1   # n = n - 1，准备计算 test(n-1)\n        jal     x1,  test      # 调用 test(n-1)，返回值在 x10\n        add     x5,  x0,  x10  # 把 test(n-1) 的结果保存到 x5（r1）\n        lw      x10, 0(x2)     # 重新取出原来的 n（之前存在栈顶）\n        sw      x5,  0(x2)     # 把 r1 存回栈顶，覆盖原 n，留待后用\n        addi    x10, x10, -2   # n = n - 2，准备计算 test(n-2)\n        jal     x1,  test      # 调用 test(n-2)，返回值在 x10（r2）\n        lw      x5,  0(x2)     # 取出第一次的 r1\n        addi    x6, x0,  2     # x6 = 2\n        mul     x5,  x5,  x6   # r1 = r1 * 2\n        addi    x6, x0,  3     # x6 = 3\n        mul     x10, x10, x6   # r2 = r2 * 3\n        add     x10, x10, x5   # 返回值 = 3*r2 + 2*r1\n      #--------------------销毁栈帧------------------------\n        addi    x2,  x2,  4         # sp += 8\n        jalr    x0, 0(x1)           # return\n      #---------------------------------------------------\nret1:   addi    x10, x0, 1\n        jalr    x0, 0(x1)\nret0:   add     x10, x0, x0\n        jalr    x0, 0(x1)\n```\n\n\n---\n# 浮点数\n### 进制转换\n![[./static/进制转换.png]]\n### 二进制整数的编码\n![[./static/原码反码补码.png]]\n注:\n1. 原码和反码最好先转换为10进制进行运算再转换为二进制,而补码可以直接进行二进制的加减运算.\n2. 饱和算数:当溢出时强行变为边界值,下溢出->最小值(-128),上溢出->(127).\n3. 小数的负数(补码):小数负数的补码的符号位在整数第一位,如1.101\n4. 对于进制转换:对于负数,先求出对应的正数的二进制原码,然后得到负数的二进制原码(直接将整数部分的符号位变为1),再得到负数的补码(取反加一),最后转变为目标进制.需要注意的是,此时扩展不足的位数时,左边应该补1,右边补0.\n\n### IEEE754浮点数\n##### 浮点数的IEEE表示\n$$\n{(-1)}^S \\times M \\times 2^E\n$$\n\t其中S,M,E分别为符号位,尾数位,阶码.\n$$\n精度\n\\begin{cases}\n单精度: float,32bits(1+8+23) \\implies \\approx 7位_{10} \\\\\n双精度: double,64bits(1+11+52) \\implies \\approx 16位_{10} \\\\\n扩展精度(Intel): 80bits(1+15+64)\n\\end{cases}\n\n$$\n##### 浮点数的运算\n以$-63.25_{10}$为例:\n1. 将正数二进制化: $63.25_{10}=111111.01_2$\n2. 科学计数法: $-111111.01_2=-1.1111101_2 \\times 2^5$\n3. 确定S,E,M: $S=1,E=(2^{8-1}-1)+5=10000100_2,M=1.1111101\\ 0000000000000000$\n\t_S,E,M的求法_:\n\tS: 符号位,正为0,负为1\n\tE: 阶码, 记偏移量$offset=2^{k-1}-1$,其中k是E的位数,则$E=exp+offset$,其中exp\n\t是科学计数法中2的指数\n\tM: 尾数位,默认为1.xxx(规格化),整数位的1忽略,小数位少的用0补全,多的截断.\n4. 拼接浮点数: $S|E|M \\implies 1\\ 10000100\\ 11111010000000000000000$\n\n##### 规格化数与非规格化数\n规格化数: 尾数位为1.xxx\n非规格化数: 尾数位为0.xxx , 指数位为全0.\n规格化数的取值范围: 设$offset=2^{k-1}-1$,则规格化数的取值范围为: `[-offset+1,offset]`.\n规格化数的准确表示的个数:\n1. $N(E)=2^E-2$ \n\t(即 $000...001~111...110$ )\n\t**指数位不能取****0000(****非规格化****)****和****1111(NaN,****无穷****)** **!!!!!**\n2. $N(M)$ = $2^M$\n3. $N(S)$ = $2$\n\t则准确表示的个数 $N=N(E) \\times N(M) \\times N(S)$.\n非规格化数准确表示的个数:\n\t类似于规格化,但是N(E)=1,(非规格化数的指数位为全0),\n\t准确表示的个数 $N=N(E) \\times N(M) \\times N(S)$.\n\n---\n# 单周期CPU\n##### 各类型元件:\n1. **程序计数器（PC, Program Counter）**：存储下一条要执行的指令的地址。\n2. **指令存储器（IM, Instruction Memory）**：根据PC提供的地址，读取对应的指令。\n3. **寄存器文件（Register Files）**：包含多个通用寄存器，用于存储数据和地址。\n4. **算术逻辑单元（ALU）**：执行算术和逻辑运算。\n5. **数据存储器（DM, Data Memory）**：用于存储和读取数据。\n6. **控制单元（Controller）**：解析指令并生成控制信号，协调CPU各部件的操作。\n7. **立即数生成器 (ImmGen)** ：从指令中提取立即数，并进行符号扩展或零扩展。\n8. **多路选择器（MUX）**：根据控制信号，从多个输入中选择一个输出。\n\n### 控制信号\n##### 控制信号(常规)\n\n| 控制信号名    | 控制的部件           | 功能说明         | 取值含义                     |\n| -------- | --------------- | ------------ | ------------------------ |\n| RegDst   | 寄存器堆（写入目标寄存器选择） | 决定写入哪个寄存器    | 0: I型（rt）<br>1: R型（rd字段） |\n| ALUSrc   | ALU的第二个操作数来源    | 选择ALU第二输入    | 0: 寄存器（R型）<br>1: 立即数（I型） |\n| MemtoReg | 寄存器写回数据选择       | 决定写回寄存器的数据来源 | 0: ALU结果<br>1: 内存输出      |\n| RegWrite | 寄存器堆写使能         | 是否允许寄存器写入    | 1: 写入寄存器<br>0: 不写入       |\n| MemRead  | 数据存储器           | 是否允许读出数据     | 1: 允许读（lw）               |\n| MemWrite | 数据存储器           | 是否允许写入数据     | 1: 允许写（sw）               |\n| Branch   | 分支控制            | 是否执行分支       | 1: 分支指令有效（beq）           |\n| Jump     | 跳转控制            | 是否跳转         | 1: 跳转指令有效                |\n##### 控制信号(ALUOp&ALUControl)\n\n| ALUOp | 含义（指令类型）          | 预期ALUControl | 对应的MIPS指令示例              |\n| ----- | ----------------- | ------------ | ------------------------ |\n| 00    | LW/SW（Load/Store） | 0010（加法）     | 计算存储器地址（基址+偏移量）          |\n| 01    | BEQ（Branch Equal） | 0110（减法）     | 计算 R1 - R2，检查结果是否为0      |\n| 10    | R-Type（寄存器类型）     | 由 Funct 字段决定 | Add, Sub, And, Or, SLT 等 |\n| 11    | J-Type（跳转类型）      | 不使用          | J-Type 指令通常不经过 ALU       |\n\n| ALUControl | ALU 执行的运算           | 典型场景 / 指令      |\n| ---------- | ------------------- | -------------- |\n| 0010       | 加法 (A + B)          | lw/sw 地址计算，add |\n| 0110       | 减法 (A – B)          | beq 判 0，sub    |\n| 0000       | 按位与 (A & B)         | and            |\n| 0001       | 按位或 (A \\| B)        | or             |\n| 0111       | 置小于 (A < B ? 1 : 0) | slt            |\n| 1100       | 按位或非 (A NOR B)      | nor（部分教材实现）    |\n\t当ALUOp为10(R)时,ALU Control Input根据指令的Funct字段来决定ALU实际执行的操作.\n\n##### 各指令类型的指令字\n![[./static/各类型指令二进制字段.jpg]]\n\n### 数据通路\n##### 取指令数据通路\n从指令存储器取出下一条要执行的指令.\nPC (Program Counter):保存当前执行的指令的地址.\n指令存储器(IM,Instruction Memory):根据PC地址输出对应的32位指令字(Instruction).\n主要操作:\n\t`Instruction = Mem[PC]`\n\t`PC = PC + 4`\n![[./static/取指令数据通路.png]]\n\n##### R型指令数据通路:\n以add为例,从IM传入的指令字,被切割成各个字段(Rs,Rt,Rd),经由寄存器组存储,在经过运算器写入结果.\n对于R型指令(如add):寄存器组将R1#,R2#两个地址的数值取出,经由ALU进行加法运算,\n得到运算结果WD,最后写入W#地址的内存.\n![[./static/R型指令数据通路.png]]\n![[./static/R通路.png]]\n\n##### I型指令数据通路\n以lw为例,译码阶段从指令字中读取出Rs#,Rt#和imm(立即数),对于imm通过立即数生成器(ImmGen)符号扩展成32位,将其与Rs进行加法运算,\n访存:\n\t对于算术类(addi,andi,ori):不访存,\n\t对于lw:**_用_****_ALU_****_的运算结果作为地址传入数据存储器_****_,_****_进行读操作_**,最后将结果写回寄存器组.\n![[./static/I型指令数据通路.png]]\n![[./static/I通路.png]]\n\n##### S型指令数据通路\n以sw为例,和lw相似,但是Rt作为参数,将Rt对应的数值,\n以Rs的地址+imm立即数(offset)作为地址,**传入数据存储器****,****进行写操作****.\n![[./static/S型指令数据通路.png]]\n\n##### B型指令数据通路\n以beq为例:\n![[./static/B通路.png]]\n\n\n---\n# 流水线\n### 单周期CPU流程\n\t取指令 -> 译码 -> 执行 -> 访存 -> 写入.\n\t   IF      ID      EX     MEM    WB\n\t在实际操作中,使用四个流水线寄存器组(IF/ID,ID/EX,EX/MEM,MEM/WB)来稳定控制流水线的周期相同.\n\t\n![[./static/流水线.png]]\n\t多周期流水线图:\n![[./static/多周期流水线图.png]]\n### 衡量流水线性能的指标\n在一个时空图中:\n![[static/时空图.png]]\n1. 流水线的吞吐率: 单位时间内流水线完成的的任务数量.$$TP=\\frac{任务数}{所用总时间}$$\n2. 加速比:$$加速比=\\frac{不使用流水线的时间}{使用流水线的时间}$$\n3. 流水线效率: 在时空图中的体现就是$$流水线效率=\\frac{有部件的格子数}{外围矩形的鸽子总数}$$\n\n### 冒险\n##### 冒险的分类\n- 结构冒险: 所需的部件正在被占用.\n- 数据冒险: 需要等待先前的指令完成数据读写.\n- 控制冒险: 对控制行为的决策依赖于先前的指令.\n##### 结构冒险\n- 最常见的结构冒险: 冯诺依曼结构中不区分指令存储器和数据存储器而只是用一个存储器导致的结构冒险.\n- 结构冒险举例:\n\t单端口存储器：只能在一个周期内同时做「取指」或「访存数据」，不能两者同时.\n\t→ 即：IF 阶段和MEM 阶段不能在同一个周期同时执行.\n##### 数据冒险\n数据冒险的解决方法:\n1. 旁路转发: 如果要用到数据时还未算出结果时可以使用.\n\t可以借助**数据冒险的检测**:\n\t- `EM/MEM.rd == ID/EX.rs1(或rs2)`\n\t- `MEM/WB.rd == ID/EX.rs1(或rs2)`\n\t和**Forwarding Unit(转发单元)** 来控制数据转发,直接把还没写回寄存器的数据提供给需要的指令,功能如下:\n\n| **编码** | **含义**        | **作用**                              |\n| ------ | ------------- | ----------------------------------- |\n| **00** | 不转发           | 数据来自 ID/EX 寄存器（默认值）                 |\n| **01** | EX/MEM 转发     | 数据来自 EX/MEM 寄存器（前一条指令的 ALU 结果）      |\n| **10** | MEM/WB 转发     | 数据来自 MEM/WB 寄存器（前前条指令的结果，或 load 结果） |\n| **11** | 保留或用于<br>特殊情况 | -                                   |\n\t**不能旁路到过去的时间**.这个性质也使得旁路不总能使用.\n\t![[旁路.png]]\n2. 添加阻塞或空指令(NOP): 适用于旁路不能解决的情况,如WB在ID后的情形:\n\t![[不能使用旁路的情形.png]]\n\t- 阻塞法:\n\t![[Junk.png]]\n\t- NOP法:\n\t![[Nop.png]]\n3. 重排代码: 将lw和sw之类的指令和使用它们产生出的资源的指令隔开.\n\t![[调整代码.png]]\n\n\n##### 控制冒险\n\n---\n# 内存\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
}